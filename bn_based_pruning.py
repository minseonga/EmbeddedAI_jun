"""
ğŸ”§ YOLO11 BN-Based Structured Pruning

ì´ ë°©ë²•ì€ BatchNormì˜ gamma(scale) íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 
ì¤‘ìš”í•˜ì§€ ì•Šì€ ì±„ë„ì„ ì‹ë³„í•˜ê³  ì œê±°í•©ë‹ˆë‹¤.

í•µì‹¬ ì•„ì´ë””ì–´:
- BNì˜ gammaê°€ ì‘ìœ¼ë©´ í•´ë‹¹ ì±„ë„ì€ ì¤‘ìš”í•˜ì§€ ì•ŠìŒ
- gamma < thresholdì¸ ì±„ë„ì„ ì œê±°
- Conv-BN ìŒì„ í•¨ê»˜ ì²˜ë¦¬

ì°¸ê³  ë…¼ë¬¸: "Learning Efficient Convolutional Networks through Network Slimming"
https://arxiv.org/abs/1708.06519
"""

import os
import sys
import copy
import time
from pathlib import Path
from collections import OrderedDict

import torch
import torch.nn as nn
import numpy as np

from ultralytics import YOLO

try:
    from thop import profile
    HAS_THOP = True
except ImportError:
    HAS_THOP = False

ROOT = Path(__file__).resolve().parent
MODEL_PATH = ROOT / "assets/models/yolo11n_hand_pose.pt"
IMG_SIZE = 640


# =========================================================
# BN Gamma ê¸°ë°˜ ì±„ë„ ì¤‘ìš”ë„ ë¶„ì„
# =========================================================

def analyze_bn_gamma(model):
    """ëª¨ë“  BN ë ˆì´ì–´ì˜ gamma ë¶„ì„"""
    bn_info = []
    
    for name, m in model.named_modules():
        if isinstance(m, nn.BatchNorm2d):
            gamma = m.weight.data.abs()
            bn_info.append({
                'name': name,
                'module': m,
                'channels': m.num_features,
                'gamma': gamma,
                'gamma_mean': gamma.mean().item(),
                'gamma_sorted': gamma.sort()[0],
            })
    
    return bn_info


def get_pruning_threshold(model, prune_ratio):
    """
    ì „ì²´ BN gammaë¥¼ ëª¨ì•„ì„œ prune_ratioì— í•´ë‹¹í•˜ëŠ” threshold ê³„ì‚°
    
    ì˜ˆ: prune_ratio=0.3 â†’ í•˜ìœ„ 30% gamma ê°’ì„ thresholdë¡œ ì„¤ì •
    """
    all_gamma = []
    
    for name, m in model.named_modules():
        if isinstance(m, nn.BatchNorm2d):
            all_gamma.append(m.weight.data.abs().clone())
    
    all_gamma = torch.cat(all_gamma)
    sorted_gamma, _ = torch.sort(all_gamma)
    
    # í•˜ìœ„ prune_ratio% ì— í•´ë‹¹í•˜ëŠ” ê°’
    threshold_idx = int(len(sorted_gamma) * prune_ratio)
    threshold = sorted_gamma[threshold_idx].item()
    
    return threshold


def get_channel_mask(bn_layer, threshold, min_channels=8):
    """
    BN layerì˜ gamma ê¸°ë°˜ìœ¼ë¡œ ìœ ì§€í•  ì±„ë„ ë§ˆìŠ¤í¬ ìƒì„±
    
    Returns:
        mask: ìœ ì§€í•  ì±„ë„ True, ì œê±°í•  ì±„ë„ False
        keep_indices: ìœ ì§€í•  ì±„ë„ ì¸ë±ìŠ¤
    """
    gamma = bn_layer.weight.data.abs()
    mask = gamma > threshold
    
    # ìµœì†Œ ì±„ë„ ìˆ˜ ë³´ì¥
    if mask.sum() < min_channels:
        # ê°€ì¥ í° gammaë¥¼ ê°€ì§„ min_channels ê°œ ìœ ì§€
        _, indices = torch.topk(gamma, min_channels)
        mask = torch.zeros_like(mask, dtype=torch.bool)
        mask[indices] = True
    
    keep_indices = mask.nonzero().squeeze(-1)
    
    return mask, keep_indices


# =========================================================
# Conv-BN ìŒ Pruning
# =========================================================

def prune_conv_bn_pair(conv, bn, keep_indices, next_conv=None):
    """
    Conv + BN ìŒì˜ ì¶œë ¥ ì±„ë„ì„ pruning
    
    Args:
        conv: Conv2d ë ˆì´ì–´
        bn: BatchNorm2d ë ˆì´ì–´
        keep_indices: ìœ ì§€í•  ì±„ë„ ì¸ë±ìŠ¤
        next_conv: ë‹¤ìŒ Conv2d (ì…ë ¥ ì±„ë„ ì¡°ì •ìš©)
    """
    n_keep = len(keep_indices)
    
    # Conv ì¶œë ¥ ì±„ë„ pruning
    conv.weight.data = conv.weight.data[keep_indices]
    conv.out_channels = n_keep
    if conv.bias is not None:
        conv.bias.data = conv.bias.data[keep_indices]
    
    # BN ë™ê¸°í™”
    bn.weight.data = bn.weight.data[keep_indices]
    bn.bias.data = bn.bias.data[keep_indices]
    bn.running_mean.data = bn.running_mean.data[keep_indices]
    bn.running_var.data = bn.running_var.data[keep_indices]
    bn.num_features = n_keep
    
    # ë‹¤ìŒ Convì˜ ì…ë ¥ ì±„ë„ ì¡°ì •
    if next_conv is not None and next_conv.groups == 1:
        next_conv.weight.data = next_conv.weight.data[:, keep_indices]
        next_conv.in_channels = n_keep


# =========================================================
# YOLO11 ì „ì²´ ëª¨ë¸ Pruning
# =========================================================

def prune_yolo11_bn_based(model_path, prune_ratio=0.3):
    """
    BN Gamma ê¸°ë°˜ YOLO11 Structured Pruning
    
    ì£¼ì˜: YOLO11ì˜ skip connectionê³¼ Concat ë•Œë¬¸ì—
    ì¼ë¶€ ë ˆì´ì–´ë§Œ ì•ˆì „í•˜ê²Œ pruning ê°€ëŠ¥
    """
    print(f"\n{'='*70}")
    print(f"ğŸ”§ YOLO11 BN-Based Structured Pruning")
    print(f"   Prune ratio: {prune_ratio*100:.0f}%")
    print(f"{'='*70}")
    
    # ëª¨ë¸ ë¡œë“œ
    yolo = YOLO(model_path)
    model = copy.deepcopy(yolo.model)
    model.eval()
    
    # Before ì¸¡ì •
    before_params = sum(p.numel() for p in model.parameters())
    print(f"\nBefore: {before_params/1e6:.3f}M params")
    
    # Threshold ê³„ì‚°
    threshold = get_pruning_threshold(model, prune_ratio)
    print(f"Gamma threshold: {threshold:.4f}")
    
    # BN gamma ë¶„ì„
    bn_info = analyze_bn_gamma(model)
    print(f"ì´ BN ë ˆì´ì–´: {len(bn_info)}ê°œ")
    
    # === ì•ˆì „í•œ Pruning: ë…ë¦½ì ì¸ Conv-BN ìŒë§Œ ì²˜ë¦¬ ===
    # YOLOì˜ ì²« ëª‡ ê°œ ë ˆì´ì–´ (Concat/Skip ì˜í–¥ ì—†ëŠ” ë¶€ë¶„)
    
    pruned_count = 0
    
    # model.model ë‚´ì˜ ê° ë¸”ë¡ ì²˜ë¦¬
    for block_idx, block in enumerate(model.model):
        block_type = type(block).__name__
        
        # ë…ë¦½ì ì¸ Conv ë¸”ë¡ë§Œ ì²˜ë¦¬ (block_idx 0, 1ë§Œ - ë‚˜ë¨¸ì§€ëŠ” skip connection ì˜í–¥)
        if block_type == 'Conv' and block_idx <= 1:
            conv = block.conv
            bn = block.bn
            
            # RGB ì…ë ¥ ìŠ¤í‚µ
            if conv.in_channels == 3:
                continue
            
            # ì±„ë„ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ìŠ¤í‚µ
            if conv.out_channels <= 16:
                continue
            
            # Gamma ê¸°ë°˜ ë§ˆìŠ¤í¬ ìƒì„±
            mask, keep_indices = get_channel_mask(bn, threshold, min_channels=8)
            
            if len(keep_indices) < conv.out_channels:
                old_ch = conv.out_channels
                
                # Pruning ì ìš©
                prune_conv_bn_pair(conv, bn, keep_indices)
                
                pruned_count += 1
                print(f"  âœ‚ï¸ Block {block_idx} ({block_type}): {old_ch} -> {len(keep_indices)} channels")
    
    print(f"\nì´ {pruned_count}ê°œ ë¸”ë¡ pruned")
    
    # After ì¸¡ì •
    after_params = sum(p.numel() for p in model.parameters())
    print(f"After: {after_params/1e6:.3f}M params")
    print(f"Reduction: {(1-after_params/before_params)*100:.1f}%")
    
    # Forward í…ŒìŠ¤íŠ¸
    try:
        dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)
        with torch.no_grad():
            output = model(dummy)
        print("âœ… Forward ì„±ê³µ!")
        return model, True
    except Exception as e:
        print(f"âŒ Forward ì‹¤íŒ¨: {e}")
        return model, False


# =========================================================
# ë” ê³µê²©ì ì¸ ë°©ë²•: Filter Reconstruction
# =========================================================

def slim_yolo_by_width(model_path, width_mult=0.5):
    """
    YOLO ëª¨ë¸ì˜ widthë¥¼ ì¤„ì—¬ ë” ì‘ì€ ëª¨ë¸ ìƒì„±
    
    ì´ ë°©ë²•ì€:
    1. ê° Convì˜ ì¶œë ¥ ì±„ë„ì„ width_mult ë¹„ìœ¨ë¡œ ì¤„ì„
    2. ë‹¤ìŒ ë ˆì´ì–´ì˜ ì…ë ¥ ì±„ë„ë„ ë§ì¶¤
    3. ìƒˆ ëª¨ë¸ì„ ìƒì„±í•˜ê³  ê°€ì¥ ì¤‘ìš”í•œ ì±„ë„ì˜ weight ë³µì‚¬
    
    ì£¼ì˜: í•™ìŠµ ì—†ì´ëŠ” ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ
    """
    print(f"\n{'='*70}")
    print(f"ğŸ”§ YOLO11 Width Slimming")
    print(f"   Width multiplier: {width_mult}")
    print(f"{'='*70}")
    
    yolo = YOLO(model_path)
    model = yolo.model.eval()
    
    before_params = sum(p.numel() for p in model.parameters())
    print(f"Before: {before_params/1e6:.3f}M params")
    
    # ëª¨ë¸ êµ¬ì¡° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    yaml_cfg = model.yaml
    print(f"Original scale: {yaml_cfg.get('scale', 'n')}")
    
    # scales ìˆ˜ì •ìœ¼ë¡œ ë” ì‘ì€ ëª¨ë¸ ìƒì„±ì€ YOLO ì¬í•™ìŠµì´ í•„ìš”
    # ëŒ€ì‹ , í˜„ì¬ weightì—ì„œ ì¤‘ìš”í•œ ì±„ë„ë§Œ ì„ íƒí•˜ëŠ” ë°©ì‹ ì‚¬ìš©
    
    slim_count = 0
    
    for name, module in model.named_modules():
        if type(module).__name__ == 'Conv' and hasattr(module, 'conv') and hasattr(module, 'bn'):
            conv = module.conv
            bn = module.bn
            
            # ìŠ¤í‚µ ì¡°ê±´
            if conv.in_channels == 3:
                continue
            if conv.out_channels <= 8:
                continue
            
            # Detection head ìŠ¤í‚µ
            if 'model.23' in name:
                continue
            
            # ìƒˆ ì±„ë„ ìˆ˜
            old_ch = conv.out_channels
            new_ch = max(8, int(old_ch * width_mult))
            new_ch = (new_ch // 8) * 8  # 8ì˜ ë°°ìˆ˜
            new_ch = max(8, min(new_ch, old_ch))
            
            if new_ch < old_ch:
                # BN gamma ê¸°ë°˜ ì¤‘ìš” ì±„ë„ ì„ íƒ
                gamma = bn.weight.data.abs()
                _, keep_indices = torch.topk(gamma, new_ch)
                keep_indices = keep_indices.sort().values
                
                # Pruning
                conv.weight.data = conv.weight.data[keep_indices]
                conv.out_channels = new_ch
                if conv.bias is not None:
                    conv.bias.data = conv.bias.data[keep_indices]
                
                bn.weight.data = bn.weight.data[keep_indices]
                bn.bias.data = bn.bias.data[keep_indices]
                bn.running_mean.data = bn.running_mean.data[keep_indices]
                bn.running_var.data = bn.running_var.data[keep_indices]
                bn.num_features = new_ch
                
                slim_count += 1
    
    print(f"ì´ {slim_count}ê°œ ë ˆì´ì–´ slimmed")
    
    after_params = sum(p.numel() for p in model.parameters())
    print(f"After: {after_params/1e6:.3f}M params")
    print(f"Reduction: {(1-after_params/before_params)*100:.1f}%")
    
    return model


# =========================================================
# ê°€ì¥ í˜„ì‹¤ì ì¸ ë°©ë²•: Sparsity Training + Pruning
# =========================================================

def train_with_sparsity(model, sparsity_lambda=1e-4):
    """
    BN gammaì— L1 regularizationì„ ì¶”ê°€í•˜ì—¬ sparsity ìœ ë„
    
    í•™ìŠµ ì‹œ loss += sparsity_lambda * sum(|gamma|)
    
    ì´ë ‡ê²Œ í•™ìŠµí•˜ë©´ ë¶ˆí•„ìš”í•œ ì±„ë„ì˜ gammaê°€ 0ì— ê°€ê¹Œì›Œì§
    â†’ ì´í›„ pruningì´ ë” íš¨ê³¼ì 
    """
    # ì´ í•¨ìˆ˜ëŠ” í•™ìŠµ ì½”ë“œì— í†µí•©ë˜ì–´ì•¼ í•¨
    sparsity_loss = 0
    
    for m in model.modules():
        if isinstance(m, nn.BatchNorm2d):
            sparsity_loss += m.weight.abs().sum()
    
    return sparsity_loss * sparsity_lambda


# =========================================================
# ë²¤ì¹˜ë§ˆí¬
# =========================================================

def benchmark(model, name, device='cpu'):
    if model is None:
        return {'name': name, 'params': 0, 'flops': 0, 'fps': 0}
    
    model = model.to(device).eval()
    params = sum(p.numel() for p in model.parameters()) / 1e6
    
    flops = 0.0
    try:
        dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)
        if HAS_THOP:
            macs, _ = profile(model, inputs=(dummy,), verbose=False)
            flops = macs / 1e9
            for m in model.modules():
                for attr in ['total_ops', 'total_params']:
                    if hasattr(m, attr):
                        delattr(m, attr)
    except:
        pass
    
    fps = 0.0
    try:
        dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)
        with torch.no_grad():
            for _ in range(5):
                model(dummy)
        
        times = []
        with torch.no_grad():
            for _ in range(20):
                t0 = time.time()
                model(dummy)
                times.append(time.time() - t0)
        fps = 1.0 / (sum(times) / len(times))
    except:
        pass
    
    return {'name': name, 'params': params, 'flops': flops, 'fps': fps}


def main():
    print("=" * 70)
    print("ğŸš€ YOLO11 ëŒ€ì²´ Pruning ë°©ë²• í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    if not MODEL_PATH.exists():
        print(f"âŒ ëª¨ë¸ ì—†ìŒ: {MODEL_PATH}")
        return
    
    results = []
    
    # 1. Baseline
    print("\n[1] Baseline...")
    yolo_base = YOLO(MODEL_PATH)
    base_result = benchmark(yolo_base.model, "Baseline")
    results.append(base_result)
    print(f"   Params: {base_result['params']:.3f}M, FLOPs: {base_result['flops']:.3f}G")
    
    # 2. BN-based Pruning
    print("\n[2] BN-Based Pruning...")
    for ratio in [0.3, 0.5]:
        model, success = prune_yolo11_bn_based(MODEL_PATH, prune_ratio=ratio)
        if success:
            result = benchmark(model, f"BN_Pruning_{int(ratio*100)}%")
            results.append(result)
            print(f"   Params: {result['params']:.3f}M, FPS: {result['fps']:.1f}")
    
    # 3. Width Slimming
    print("\n[3] Width Slimming...")
    for mult in [0.75, 0.5]:
        try:
            model = slim_yolo_by_width(MODEL_PATH, width_mult=mult)
            
            # Forward í…ŒìŠ¤íŠ¸
            dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)
            try:
                with torch.no_grad():
                    model(dummy)
                result = benchmark(model, f"Width_{int(mult*100)}%")
                results.append(result)
                print(f"   Params: {result['params']:.3f}M, FPS: {result['fps']:.1f}")
            except Exception as e:
                print(f"   âŒ Forward ì‹¤íŒ¨: {str(e)[:50]}")
        except Exception as e:
            print(f"   âŒ Slimming ì‹¤íŒ¨: {e}")
    
    # ê²°ê³¼
    print("\n" + "=" * 70)
    print(f"{'Model':<25} | {'Params(M)':<12} | {'FLOPs(G)':<12} | {'FPS':<10}")
    print("-" * 70)
    for r in results:
        print(f"{r['name']:<25} | {r['params']:<12.3f} | {r['flops']:<12.3f} | {r['fps']:<10.1f}")
    print("=" * 70)
    
    print("\nğŸ“ ì°¸ê³ :")
    print("- BN-Based Pruning: ì•ˆì „í•œ ë ˆì´ì–´ë§Œ pruning (ì¼ë¶€ë§Œ ê°ì†Œ)")
    print("- Width Slimming: ì±„ë„ ìˆ˜ë¥¼ ì¤„ì´ì§€ë§Œ forward í˜¸í™˜ì„± ë¬¸ì œ ê°€ëŠ¥")
    print("- ìµœì„ ì˜ ë°©ë²•: Sparsity Training í›„ Pruning (ì¬í•™ìŠµ í•„ìš”)")


if __name__ == "__main__":
    main()
