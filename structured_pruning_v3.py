"""
ğŸ”§ YOLO11 Structured Pruning v3 - Forward Hook ê¸°ë°˜

í•µì‹¬ ì „ëµ:
1. Forward hookìœ¼ë¡œ ê° ë ˆì´ì–´ì˜ ì‹¤ì œ ì…ì¶œë ¥ shape ì¶”ì 
2. ì—°ê²°ëœ ë ˆì´ì–´ë“¤ì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ìŒ
3. ê·¸ë£¹ ë‹¨ìœ„ë¡œ ë™ì‹œì— pruning
"""

import os
import sys
import copy
import time
from pathlib import Path
from collections import defaultdict

import torch
import torch.nn as nn
import numpy as np

from ultralytics import YOLO

try:
    from thop import profile
    HAS_THOP = True
except ImportError:
    HAS_THOP = False

ROOT = Path(__file__).resolve().parent
MODEL_PATH = ROOT / "assets/models/yolo11n_hand_pose.pt"
IMG_SIZE = 640


def compute_importance(weight: torch.Tensor) -> torch.Tensor:
    """L1 norm ê¸°ë°˜ ì±„ë„ ì¤‘ìš”ë„"""
    if len(weight.shape) == 4:
        return weight.abs().sum(dim=(1, 2, 3))
    elif len(weight.shape) == 2:
        return weight.abs().sum(dim=1)
    return weight.abs()


class LayerInfo:
    """ë ˆì´ì–´ ì •ë³´ ì €ì¥"""
    def __init__(self, name, module, input_shape, output_shape):
        self.name = name
        self.module = module
        self.input_shape = input_shape
        self.output_shape = output_shape
        self.input_channels = input_shape[1] if len(input_shape) == 4 else None
        self.output_channels = output_shape[1] if len(output_shape) == 4 else None


def trace_layer_connections(model):
    """Forward passë¥¼ í†µí•´ ê° ë ˆì´ì–´ì˜ ì…ì¶œë ¥ shape ì¶”ì """
    layer_info = {}
    hooks = []
    
    def make_hook(name):
        def hook(module, input, output):
            if isinstance(input, tuple) and len(input) > 0:
                in_shape = input[0].shape if isinstance(input[0], torch.Tensor) else None
            else:
                in_shape = input.shape if isinstance(input, torch.Tensor) else None
            
            if isinstance(output, torch.Tensor):
                out_shape = output.shape
            elif isinstance(output, tuple) and len(output) > 0:
                out_shape = output[0].shape if isinstance(output[0], torch.Tensor) else None
            else:
                out_shape = None
            
            if in_shape is not None and out_shape is not None:
                layer_info[name] = LayerInfo(name, module, in_shape, out_shape)
        return hook
    
    # ëª¨ë“  ë ˆì´ì–´ì— hook ë“±ë¡
    for name, module in model.named_modules():
        if isinstance(module, (nn.Conv2d, nn.BatchNorm2d, nn.Linear)):
            hooks.append(module.register_forward_hook(make_hook(name)))
    
    # Forward pass
    model.eval()
    with torch.no_grad():
        dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)
        try:
            model(dummy)
        except:
            pass
    
    # Hook ì œê±°
    for h in hooks:
        h.remove()
    
    return layer_info


def build_pruning_groups(model, layer_info):
    """
    ì±„ë„ ì˜ì¡´ì„± ê¸°ë°˜ìœ¼ë¡œ pruning ê·¸ë£¹ ìƒì„±
    
    ê°™ì€ ì¶œë ¥ ì±„ë„ ìˆ˜ë¥¼ ê°€ì§„ ì—°ì†ëœ ë ˆì´ì–´ë“¤ì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ìŒ
    """
    groups = defaultdict(list)
    
    # ì¶œë ¥ ì±„ë„ ìˆ˜ë¡œ ê·¸ë£¹í™”
    for name, info in layer_info.items():
        if info.output_channels is not None:
            groups[info.output_channels].append((name, info))
    
    return groups


def prune_layer_group(model, group_layers, prune_ratio):
    """
    ê·¸ë£¹ ë‚´ ëª¨ë“  ë ˆì´ì–´ë¥¼ ë™ì¼í•œ ë§ˆìŠ¤í¬ë¡œ pruning
    """
    if not group_layers:
        return
    
    # ê·¸ë£¹ì˜ ëŒ€í‘œ ì±„ë„ ìˆ˜
    n_channels = group_layers[0][1].output_channels
    n_keep = max(8, int(n_channels * (1 - prune_ratio)))
    n_keep = (n_keep // 8) * 8  # 8ì˜ ë°°ìˆ˜
    n_keep = max(8, min(n_keep, n_channels))
    
    if n_keep >= n_channels:
        return
    
    # ê·¸ë£¹ ë‚´ ëª¨ë“  Convì˜ ì¤‘ìš”ë„ í‰ê· 
    total_importance = torch.zeros(n_channels)
    conv_count = 0
    
    for name, info in group_layers:
        if isinstance(info.module, nn.Conv2d) and info.module.out_channels == n_channels:
            importance = compute_importance(info.module.weight.data)
            total_importance += importance
            conv_count += 1
    
    if conv_count == 0:
        return
    
    avg_importance = total_importance / conv_count
    _, keep_idx = torch.topk(avg_importance, n_keep)
    keep_idx = keep_idx.sort().values
    
    # ê·¸ë£¹ ë‚´ ëª¨ë“  ë ˆì´ì–´ pruning
    for name, info in group_layers:
        module = info.module
        
        if isinstance(module, nn.Conv2d):
            if module.out_channels == n_channels:
                # ì¶œë ¥ ì±„ë„ pruning
                module.weight.data = module.weight.data[keep_idx]
                module.out_channels = n_keep
                if module.bias is not None:
                    module.bias.data = module.bias.data[keep_idx]
        
        elif isinstance(module, nn.BatchNorm2d):
            if module.num_features == n_channels:
                module.weight.data = module.weight.data[keep_idx]
                module.bias.data = module.bias.data[keep_idx]
                module.running_mean.data = module.running_mean.data[keep_idx]
                module.running_var.data = module.running_var.data[keep_idx]
                module.num_features = n_keep


def prune_yolo11_structured(model_path, prune_ratio=0.3):
    """YOLO11 êµ¬ì¡°ì  Pruning (ì±„ë„ ê·¸ë£¹ ê¸°ë°˜)"""
    print(f"\n{'='*60}")
    print(f"ğŸ”§ YOLO11 Structured Pruning v3 (ratio: {prune_ratio*100:.0f}%)")
    print(f"{'='*60}")
    
    yolo = YOLO(model_path)
    model = copy.deepcopy(yolo.model)
    
    before_params = sum(p.numel() for p in model.parameters())
    print(f"Before: {before_params/1e6:.3f}M params")
    
    # 1. ë ˆì´ì–´ ì—°ê²° ì¶”ì 
    layer_info = trace_layer_connections(model)
    print(f"ì¶”ì ëœ ë ˆì´ì–´: {len(layer_info)}ê°œ")
    
    # 2. Pruning ê·¸ë£¹ ìƒì„±
    groups = build_pruning_groups(model, layer_info)
    print(f"ì±„ë„ ê·¸ë£¹: {len(groups)}ê°œ")
    
    # 3. ê° ê·¸ë£¹ë³„ pruning (ì‘ì€ ì±„ë„ ê·¸ë£¹ì€ ìŠ¤í‚µ)
    for n_channels, group_layers in sorted(groups.items()):
        if n_channels < 16:  # ë„ˆë¬´ ì‘ìœ¼ë©´ ìŠ¤í‚µ
            continue
        if n_channels == 3:  # RGB ì…ë ¥ ìŠ¤í‚µ
            continue
        
        # Pose head ê´€ë ¨ ìŠ¤í‚µ (63, 64 ì±„ë„)
        if any('model.23' in name for name, _ in group_layers):
            continue
        
        prune_layer_group(model, group_layers, prune_ratio)
        print(f"  âœ‚ï¸ {n_channels}ch ê·¸ë£¹: {len(group_layers)}ê°œ ë ˆì´ì–´")
    
    after_params = sum(p.numel() for p in model.parameters())
    print(f"After: {after_params/1e6:.3f}M params ({(1-after_params/before_params)*100:.1f}% â†“)")
    
    return model, yolo


def create_consistent_pruned_model(model_path, prune_ratio=0.3):
    """
    YOLO11ì„ ì¼ê´€ë˜ê²Œ pruning
    
    í•µì‹¬: ê° stageì˜ ì¶œë ¥ ì±„ë„ì„ ì¤„ì´ê³ , ëª¨ë“  ì—°ê²°ëœ ë ˆì´ì–´ ë™ê¸°í™”
    """
    print(f"\n{'='*60}")
    print(f"ğŸ”§ YOLO11 Consistent Pruning (ratio: {prune_ratio*100:.0f}%)")
    print(f"{'='*60}")
    
    yolo = YOLO(model_path)
    model = copy.deepcopy(yolo.model)
    
    before_params = sum(p.numel() for p in model.parameters())
    print(f"Before: {before_params/1e6:.3f}M params")
    
    # YOLO11nì˜ ê¸°ë³¸ ì±„ë„ êµ¬ì¡° (ìˆ˜ì •í•  íƒ€ê²Ÿ)
    # Block 0: 16, Block 1: 32
    # ì´ ì±„ë„ë“¤ì´ ì—°ê²°ë˜ì–´ ìˆìœ¼ë¯€ë¡œ í•¨ê»˜ ì¤„ì—¬ì•¼ í•¨
    
    keep_ratio = 1.0 - prune_ratio
    
    # ê° YOLO blockì˜ Conv ë ˆì´ì–´ë§Œ ì„ íƒì ìœ¼ë¡œ ì²˜ë¦¬
    # (ë…ë¦½ì ì¸ Conv ë¸”ë¡ë§Œ, Concatì— ì˜í–¥ë°›ëŠ” ê±´ ìŠ¤í‚µ)
    
    pruned_blocks = []
    
    for block_idx, block in enumerate(model.model):
        block_type = type(block).__name__
        
        # ë…ë¦½ì ì¸ Conv ë¸”ë¡ë§Œ ì²˜ë¦¬ (ì¸ë±ìŠ¤ 0, 1, 3, 5, 7)
        if block_type == 'Conv' and block_idx in [0, 1, 3, 5, 7]:
            conv = block.conv
            bn = block.bn
            
            if conv.in_channels == 3:  # ì…ë ¥ ë ˆì´ì–´ ìŠ¤í‚µ
                continue
            
            # ìƒˆ ì±„ë„ ìˆ˜
            old_ch = conv.out_channels
            new_ch = max(8, int(old_ch * keep_ratio) // 8 * 8)
            
            if new_ch >= old_ch:
                continue
            
            # ì¤‘ìš”ë„ ê¸°ë°˜ ì±„ë„ ì„ íƒ
            importance = compute_importance(conv.weight.data)
            _, keep_idx = torch.topk(importance, new_ch)
            keep_idx = keep_idx.sort().values
            
            # Conv ì¶œë ¥ pruning
            conv.weight.data = conv.weight.data[keep_idx]
            conv.out_channels = new_ch
            if conv.bias is not None:
                conv.bias.data = conv.bias.data[keep_idx]
            
            # BN ë™ê¸°í™”
            bn.weight.data = bn.weight.data[keep_idx]
            bn.bias.data = bn.bias.data[keep_idx]
            bn.running_mean.data = bn.running_mean.data[keep_idx]
            bn.running_var.data = bn.running_var.data[keep_idx]
            bn.num_features = new_ch
            
            pruned_blocks.append((block_idx, old_ch, new_ch))
    
    print(f"Pruned blocks: {pruned_blocks}")
    
    # ì´ì œ ì—°ê²°ëœ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ë ˆì´ì–´ì˜ ì…ë ¥ ì±„ë„ ì¡°ì •
    # (ì´ ë¶€ë¶„ì´ ë³µì¡í•¨ - skip connection ë•Œë¬¸ì—)
    
    after_params = sum(p.numel() for p in model.parameters())
    print(f"After: {after_params/1e6:.3f}M params ({(1-after_params/before_params)*100:.1f}% â†“)")
    
    return model, yolo


def benchmark(model, name: str, device='cpu'):
    """ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì •"""
    model = model.to(device).eval()
    
    params = sum(p.numel() for p in model.parameters()) / 1e6
    nonzero = sum((p != 0).sum().item() for p in model.parameters()) / 1e6
    
    flops = 0.0
    if HAS_THOP:
        try:
            dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)
            macs, _ = profile(model, inputs=(dummy,), verbose=False)
            flops = macs / 1e9
            for m in model.modules():
                for attr in ['total_ops', 'total_params']:
                    if hasattr(m, attr):
                        delattr(m, attr)
        except Exception as e:
            pass
    
    fps, latency = 0.0, 0.0
    try:
        dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)
        with torch.no_grad():
            for _ in range(5):
                model(dummy)
        
        times = []
        with torch.no_grad():
            for _ in range(20):
                t0 = time.time()
                model(dummy)
                times.append(time.time() - t0)
        
        fps = 1.0 / (sum(times) / len(times))
        latency = (sum(times) / len(times)) * 1000
    except Exception as e:
        print(f"  âš ï¸ Forward ì‹¤íŒ¨: {str(e)[:60]}")
    
    return {
        'name': name,
        'params': params,
        'nonzero': nonzero,
        'flops': flops,
        'fps': fps,
        'latency': latency
    }


def main():
    print("=" * 70)
    print("ğŸš€ YOLO11 Structured Pruning v3 - Forward Hook ê¸°ë°˜")
    print("=" * 70)
    
    if not MODEL_PATH.exists():
        print(f"âŒ ëª¨ë¸ ì—†ìŒ: {MODEL_PATH}")
        return
    
    results = []
    
    # 1. ì›ë³¸ ëª¨ë¸
    print("\n[1] ì›ë³¸ ëª¨ë¸...")
    yolo_base = YOLO(MODEL_PATH)
    base_result = benchmark(yolo_base.model, "Baseline")
    results.append(base_result)
    print(f"   Params: {base_result['params']:.3f}M, FLOPs: {base_result['flops']:.3f}G, FPS: {base_result['fps']:.1f}")
    
    # 2. Structured Pruning í…ŒìŠ¤íŠ¸
    print("\n[2] Structured Pruning...")
    for ratio in [0.3, 0.5]:
        try:
            model, yolo = prune_yolo11_structured(MODEL_PATH, ratio)
            result = benchmark(model, f"Structured_{int(ratio*100)}%")
            results.append(result)
            
            if result['fps'] > 0:
                print(f"   âœ… Params: {result['params']:.3f}M, FPS: {result['fps']:.1f}")
                
                # ì €ì¥
                save_path = ROOT / f"assets/models/yolo11n_pruned_v3_{int(ratio*100)}.pt"
                torch.save({'model': model.state_dict()}, save_path)
            else:
                print(f"   Forward ì‹¤íŒ¨")
        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {e}")
    
    # ê²°ê³¼
    print("\n" + "=" * 85)
    print(f"{'Model':<25} | {'Params(M)':<12} | {'FLOPs(G)':<10} | {'FPS':<8} | {'Latency(ms)':<12}")
    print("-" * 85)
    for r in results:
        print(f"{r['name']:<25} | {r['params']:<12.3f} | {r['flops']:<10.3f} | {r['fps']:<8.1f} | {r['latency']:<12.1f}")
    print("=" * 85)


if __name__ == "__main__":
    main()
