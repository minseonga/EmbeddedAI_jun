"""
ğŸ”§ YOLO11 ìˆ˜ë™ Structured Pruning 

YOLO11 ëª¨ë¸ì˜ ì±„ë„ì„ ì‹¤ì œë¡œ ì¤„ì—¬ì„œ:
- íŒŒë¼ë¯¸í„° ìˆ˜ ê°ì†Œ
- FLOPs ê°ì†Œ
- ì‹¤í–‰ ì†ë„ í–¥ìƒ

ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

ë°©ë²•: ê° ë ˆì´ì–´ì˜ weightì—ì„œ ì¤‘ìš”ë„ê°€ ë‚®ì€ ì±„ë„(í•„í„°)ì„ ì œê±°í•˜ê³ ,
      ì—°ê²°ëœ ëª¨ë“  ë ˆì´ì–´ì˜ ì°¨ì›ì„ ë§ì¶¥ë‹ˆë‹¤.
"""

import os
import sys
import copy
import time
from pathlib import Path

import torch
import torch.nn as nn
import numpy as np

from ultralytics import YOLO
from ultralytics.nn.modules import Conv, C3k2, SPPF, C2PSA, Concat

# FLOPs ì¸¡ì •
try:
    from thop import profile
    HAS_THOP = True
except ImportError:
    HAS_THOP = False
    print("âš ï¸ thop ì—†ìŒ: pip install thop")

# =========================================================
# ì„¤ì •
# =========================================================
ROOT = Path(__file__).resolve().parent
MODEL_PATH = ROOT / "assets/models/yolo11n_hand_pose.pt"
IMG_SIZE = 640


# =========================================================
# L1 Norm ê¸°ë°˜ ì±„ë„ ì¤‘ìš”ë„ ê³„ì‚°
# =========================================================
def compute_channel_importance(conv_layer: nn.Conv2d) -> torch.Tensor:
    """
    Conv2d ë ˆì´ì–´ì˜ ê° ì¶œë ¥ ì±„ë„(í•„í„°)ì˜ L1 normì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    Returns: shape (out_channels,) í…ì„œ
    """
    weight = conv_layer.weight.data  # (out_ch, in_ch, kH, kW)
    importance = weight.abs().sum(dim=(1, 2, 3))  # (out_ch,)
    return importance


def get_pruning_indices(importance: torch.Tensor, prune_ratio: float) -> tuple:
    """
    ì¤‘ìš”ë„ ê¸°ë°˜ìœ¼ë¡œ ìœ ì§€í•  ì±„ë„ê³¼ ì œê±°í•  ì±„ë„ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        keep_indices: ìœ ì§€í•  ì±„ë„ ì¸ë±ìŠ¤
        prune_indices: ì œê±°í•  ì±„ë„ ì¸ë±ìŠ¤
    """
    n_channels = len(importance)
    n_prune = int(n_channels * prune_ratio)
    n_keep = n_channels - n_prune
    
    # ìµœì†Œ 1ê°œëŠ” ìœ ì§€
    n_keep = max(n_keep, 1)
    
    # 8ì˜ ë°°ìˆ˜ë¡œ ë§ì¶¤ (GPU íš¨ìœ¨)
    n_keep = max(8, (n_keep // 8) * 8)
    n_keep = min(n_keep, n_channels)
    
    # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_indices = torch.argsort(importance, descending=True)
    keep_indices = sorted_indices[:n_keep].sort().values
    prune_indices = sorted_indices[n_keep:].sort().values
    
    return keep_indices, prune_indices


# =========================================================
# Conv + BN ë ˆì´ì–´ ì±„ë„ Pruning
# =========================================================
def prune_conv_bn(conv: nn.Conv2d, bn: nn.BatchNorm2d, keep_indices: torch.Tensor, dim: str = 'out'):
    """
    Conv2d + BatchNorm2d ë ˆì´ì–´ì˜ ì±„ë„ì„ pruningí•©ë‹ˆë‹¤.
    
    Args:
        conv: Conv2d ë ˆì´ì–´
        bn: BatchNorm2d ë ˆì´ì–´
        keep_indices: ìœ ì§€í•  ì±„ë„ ì¸ë±ìŠ¤
        dim: 'out' (ì¶œë ¥ ì±„ë„ pruning) ë˜ëŠ” 'in' (ì…ë ¥ ì±„ë„ pruning)
    """
    keep_indices = keep_indices.to(conv.weight.device)
    
    if dim == 'out':
        # ì¶œë ¥ ì±„ë„ pruning
        conv.weight.data = conv.weight.data[keep_indices]
        conv.out_channels = len(keep_indices)
        
        if conv.bias is not None:
            conv.bias.data = conv.bias.data[keep_indices]
        
        # BatchNormë„ ê°™ì´ ìˆ˜ì •
        bn.weight.data = bn.weight.data[keep_indices]
        bn.bias.data = bn.bias.data[keep_indices]
        bn.running_mean.data = bn.running_mean.data[keep_indices]
        bn.running_var.data = bn.running_var.data[keep_indices]
        bn.num_features = len(keep_indices)
        
    elif dim == 'in':
        # ì…ë ¥ ì±„ë„ pruning
        conv.weight.data = conv.weight.data[:, keep_indices]
        conv.in_channels = len(keep_indices)


def prune_conv_only_in(conv: nn.Conv2d, keep_indices: torch.Tensor):
    """Conv2dì˜ ì…ë ¥ ì±„ë„ë§Œ pruning (groups ê³ ë ¤)"""
    keep_indices = keep_indices.to(conv.weight.device)
    
    if conv.groups == 1:
        conv.weight.data = conv.weight.data[:, keep_indices]
        conv.in_channels = len(keep_indices)
    # groups > 1 ì¸ ê²½ìš° (depthwise ë“±)ì€ ë” ë³µì¡í•œ ì²˜ë¦¬ í•„ìš”


# =========================================================
# YOLO11 ë¸”ë¡ë³„ Pruning í•¨ìˆ˜
# =========================================================
def prune_yolo_conv_block(block, prune_ratio: float, prev_keep_indices=None):
    """
    YOLOì˜ Conv ë¸”ë¡ (Conv2d + BN + Act) pruning
    Returns: ìœ ì§€ëœ ì¶œë ¥ ì±„ë„ ì¸ë±ìŠ¤
    """
    conv = block.conv
    bn = block.bn
    
    # 1. ì…ë ¥ ì±„ë„ pruning (ì´ì „ ë ˆì´ì–´ì—ì„œ ì „ë‹¬ë°›ì€ ê²½ìš°)
    if prev_keep_indices is not None:
        prune_conv_only_in(conv, prev_keep_indices)
    
    # 2. ì¶œë ¥ ì±„ë„ ì¤‘ìš”ë„ ê³„ì‚° ë° pruning
    importance = compute_channel_importance(conv)
    keep_indices, _ = get_pruning_indices(importance, prune_ratio)
    prune_conv_bn(conv, bn, keep_indices, dim='out')
    
    return keep_indices


def prune_c3k2_block(block, prune_ratio: float, prev_keep_indices=None):
    """
    C3k2 ë¸”ë¡ pruning (YOLO11ì˜ í•µì‹¬ ë¸”ë¡)
    
    C3k2 êµ¬ì¡°:
    - cv1: ì…ë ¥ -> ì¤‘ê°„ ì±„ë„
    - m: ì—¬ëŸ¬ ê°œì˜ Bottleneck
    - cv2: concatëœ ì±„ë„ -> ì¶œë ¥
    """
    # cv1 pruning
    if prev_keep_indices is not None:
        prune_conv_only_in(block.cv1.conv, prev_keep_indices)
    
    cv1_importance = compute_channel_importance(block.cv1.conv)
    cv1_keep, _ = get_pruning_indices(cv1_importance, prune_ratio)
    prune_conv_bn(block.cv1.conv, block.cv1.bn, cv1_keep, dim='out')
    
    # m (Bottleneckë“¤) pruning
    # ê° Bottleneckì˜ ì…ë ¥ì€ cv1 ì¶œë ¥ì˜ ì¼ë¶€
    m_out_channels = []
    for bottleneck in block.m:
        if hasattr(bottleneck, 'cv1'):
            # Bottleneck cv1
            bn_cv1_importance = compute_channel_importance(bottleneck.cv1.conv)
            bn_cv1_keep, _ = get_pruning_indices(bn_cv1_importance, prune_ratio * 0.5)  # ëœ ê³µê²©ì ìœ¼ë¡œ
            prune_conv_bn(bottleneck.cv1.conv, bottleneck.cv1.bn, bn_cv1_keep, dim='out')
            
            # Bottleneck cv2
            prune_conv_only_in(bottleneck.cv2.conv, bn_cv1_keep)
            bn_cv2_importance = compute_channel_importance(bottleneck.cv2.conv)
            bn_cv2_keep, _ = get_pruning_indices(bn_cv2_importance, prune_ratio * 0.5)
            prune_conv_bn(bottleneck.cv2.conv, bottleneck.cv2.bn, bn_cv2_keep, dim='out')
            
            m_out_channels.append(len(bn_cv2_keep))
    
    # cv2 ì…ë ¥ ì±„ë„ ì¡°ì • (cv1 ì¶œë ¥ + m ì¶œë ¥ë“¤ì˜ concat)
    # C3k2ì˜ c (ì¤‘ê°„ ì±„ë„)ëŠ” cv1ì˜ ì¶œë ¥ ì±„ë„ ìˆ˜ì™€ ê´€ë ¨
    # ë³µì¡í•œ ì˜ì¡´ì„± ë•Œë¬¸ì— cv2ëŠ” pruningí•˜ì§€ ì•Šê±°ë‚˜ ì¶œë ¥ë§Œ pruning
    
    cv2_importance = compute_channel_importance(block.cv2.conv)
    cv2_keep, _ = get_pruning_indices(cv2_importance, prune_ratio)
    
    # cv2 ì¶œë ¥ ì±„ë„ë§Œ pruning (ì…ë ¥ì€ ë³µì¡í•œ concatì´ë¯€ë¡œ ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
    # ì£¼ì˜: ì´ë ‡ê²Œ í•˜ë©´ ë¶ˆì¼ì¹˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ
    prune_conv_bn(block.cv2.conv, block.cv2.bn, cv2_keep, dim='out')
    
    return cv2_keep


# =========================================================
# ë‹¨ìˆœí™”ëœ Pruning (Width Multiplier ë°©ì‹)
# =========================================================
def create_pruned_yolo_model(original_model_path: str, prune_ratio: float) -> nn.Module:
    """
    YOLO11 ëª¨ë¸ì„ pruningí•©ë‹ˆë‹¤.
    
    ë³µì¡í•œ ì˜ì¡´ì„± ë•Œë¬¸ì—, ê° Conv ë ˆì´ì–´ì˜ weightì—ì„œ ì¤‘ìš”ë„ê°€ ë‚®ì€ í•„í„°ë¥¼ ì œê±°í•˜ê³ 
    ìƒˆë¡œìš´ ì‘ì€ ë ˆì´ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        original_model_path: ì›ë³¸ .pt íŒŒì¼ ê²½ë¡œ
        prune_ratio: ì œê±°í•  ì±„ë„ ë¹„ìœ¨ (0.3 = 30% ì œê±°)
    
    Returns:
        Pruned PyTorch model
    """
    # ì›ë³¸ ëª¨ë¸ ë¡œë“œ
    yolo = YOLO(original_model_path)
    model = copy.deepcopy(yolo.model)
    model.eval()
    
    print(f"\n{'='*60}")
    print(f"ğŸ”§ Structured Pruning ì‹œì‘ (ratio: {prune_ratio*100:.0f}%)")
    print(f"{'='*60}")
    
    # ê° ë ˆì´ì–´ì˜ ì¤‘ìš”ë„ ê¸°ë°˜ìœ¼ë¡œ ì±„ë„ ì„ íƒ
    layers_pruned = 0
    
    for name, module in model.named_modules():
        if isinstance(module, nn.Conv2d):
            # ì…ë ¥ ì±„ë„ì´ 3ì¸ ê²½ìš° (RGB ì…ë ¥) ìŠ¤í‚µ
            if module.in_channels == 3:
                continue
            
            # ì¶œë ¥ ì±„ë„ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ìŠ¤í‚µ (ìµœì†Œ 8)
            if module.out_channels <= 8:
                continue
            
            # ë§ˆì§€ë§‰ detection head ë ˆì´ì–´ëŠ” ìŠ¤í‚µ
            if 'cv2.2' in name or 'cv3.2' in name or 'cv4' in name:
                continue
            
            # ì¤‘ìš”ë„ ê³„ì‚°
            importance = compute_channel_importance(module)
            keep_indices, _ = get_pruning_indices(importance, prune_ratio)
            
            # ì¶œë ¥ ì±„ë„ pruning
            original_out = module.out_channels
            module.weight.data = module.weight.data[keep_indices]
            module.out_channels = len(keep_indices)
            
            if module.bias is not None:
                module.bias.data = module.bias.data[keep_indices]
            
            layers_pruned += 1
    
    print(f"âœ… {layers_pruned}ê°œ ë ˆì´ì–´ pruning ì™„ë£Œ")
    
    # BatchNorm ë ˆì´ì–´ë„ ë§ì¶¤
    bn_fixed = 0
    for name, module in model.named_modules():
        if isinstance(module, nn.BatchNorm2d):
            # ì´ì „ Convì˜ ì¶œë ¥ ì±„ë„ê³¼ ë§ì¶”ê¸°
            parent_name = '.'.join(name.split('.')[:-1])
            conv_name = parent_name + '.conv' if parent_name else 'conv'
            
            # í•´ë‹¹ Conv ì°¾ê¸°
            try:
                conv = dict(model.named_modules())[conv_name.replace('.bn', '.conv')]
                if isinstance(conv, nn.Conv2d):
                    target_channels = conv.out_channels
                    if module.num_features != target_channels:
                        # BN íŒŒë¼ë¯¸í„° ì¡°ì •
                        module.num_features = target_channels
                        module.weight.data = module.weight.data[:target_channels]
                        module.bias.data = module.bias.data[:target_channels]
                        module.running_mean.data = module.running_mean.data[:target_channels]
                        module.running_var.data = module.running_var.data[:target_channels]
                        bn_fixed += 1
            except:
                pass
    
    print(f"âœ… BatchNorm {bn_fixed}ê°œ ì¡°ì • ì™„ë£Œ")
    
    return model


# =========================================================
# ë” ì•ˆì „í•œ ë°©ë²•: Weight Slicing ê¸°ë°˜ Pruning
# =========================================================
def prune_model_safe(model_path: str, prune_ratio: float):
    """
    ì•ˆì „í•œ Pruning: Convì™€ ì—°ê²°ëœ BNì„ í•¨ê»˜ ì²˜ë¦¬
    
    YOLO êµ¬ì¡°ì˜ ë³µì¡í•œ skip connectionê³¼ concat ë•Œë¬¸ì—,
    ëª¨ë“  ë ˆì´ì–´ë¥¼ ë™ì‹œì— ì²˜ë¦¬í•˜ì§€ ì•Šê³ 
    ë…ë¦½ì ì¸ Conv-BN ìŒë§Œ pruningí•©ë‹ˆë‹¤.
    """
    yolo = YOLO(model_path)
    model = yolo.model
    model.eval()
    
    print(f"\n{'='*60}")
    print(f"ğŸ”§ Safe Structured Pruning (ratio: {prune_ratio*100:.0f}%)")
    print(f"{'='*60}")
    
    before_params = sum(p.numel() for p in model.parameters())
    print(f"Before: {before_params/1e6:.3f}M params")
    
    # Ultra lytics YOLOì˜ Conv ë¸”ë¡ (conv + bn + act)ì„ ì°¾ì•„ì„œ ì²˜ë¦¬
    pruned_blocks = 0
    
    for name, module in list(model.named_modules()):
        # Ultralytics Conv ë¸”ë¡ ì°¾ê¸°
        if type(module).__name__ == 'Conv' and hasattr(module, 'conv') and hasattr(module, 'bn'):
            conv = module.conv
            bn = module.bn
            
            # ìŠ¤í‚µ ì¡°ê±´
            if conv.in_channels == 3:  # ì…ë ¥ ë ˆì´ì–´
                continue
            if conv.out_channels <= 8:  # ë„ˆë¬´ ì‘ìŒ
                continue
            if 'head' in name.lower():  # Detection head
                continue
            
            # ì¤‘ìš”ë„ ê³„ì‚°
            importance = compute_channel_importance(conv)
            keep_indices, _ = get_pruning_indices(importance, prune_ratio)
            n_keep = len(keep_indices)
            
            if n_keep >= conv.out_channels:
                continue  # ë³€í™” ì—†ìŒ
            
            # ì¶œë ¥ ì±„ë„ pruning
            conv.weight.data = conv.weight.data[keep_indices]
            conv.out_channels = n_keep
            if conv.bias is not None:
                conv.bias.data = conv.bias.data[keep_indices]
            
            # BatchNorm ë™ê¸°í™”
            bn.weight.data = bn.weight.data[keep_indices]
            bn.bias.data = bn.bias.data[keep_indices]
            bn.running_mean.data = bn.running_mean.data[keep_indices]
            bn.running_var.data = bn.running_var.data[keep_indices]
            bn.num_features = n_keep
            
            pruned_blocks += 1
            print(f"  âœ‚ï¸ {name}: {conv.out_channels + len(keep_indices) - n_keep} -> {n_keep} channels")
    
    after_params = sum(p.numel() for p in model.parameters())
    print(f"\nAfter: {after_params/1e6:.3f}M params")
    print(f"Reduction: {(1 - after_params/before_params)*100:.1f}%")
    print(f"âœ… {pruned_blocks}ê°œ ë¸”ë¡ pruning ì™„ë£Œ")
    
    return model, yolo


# =========================================================
# ë©”ì¸ ë²¤ì¹˜ë§ˆí¬
# =========================================================
def benchmark_model(model, name: str, device='cpu'):
    """ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì •"""
    model = model.to(device).eval()
    
    # íŒŒë¼ë¯¸í„° ìˆ˜
    params = sum(p.numel() for p in model.parameters()) / 1e6
    
    # Non-zero íŒŒë¼ë¯¸í„°
    nonzero = sum((p != 0).sum().item() for p in model.parameters()) / 1e6
    
    # FLOPs
    flops = 0.0
    if HAS_THOP:
        try:
            dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)
            macs, _ = profile(model, inputs=(dummy,), verbose=False)
            flops = macs / 1e9
            
            # thop ì„ì‹œ ì†ì„± ì œê±°
            for m in model.modules():
                for attr in ['total_ops', 'total_params']:
                    if hasattr(m, attr):
                        delattr(m, attr)
        except Exception as e:
            print(f"  âš ï¸ FLOPs ì¸¡ì • ì‹¤íŒ¨: {e}")
    
    # ì†ë„ ì¸¡ì •
    dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)
    
    # Warmup
    with torch.no_grad():
        for _ in range(10):
            try:
                model(dummy)
            except:
                break
    
    # Measure
    times = []
    with torch.no_grad():
        for _ in range(30):
            try:
                t0 = time.time()
                model(dummy)
                times.append(time.time() - t0)
            except:
                break
    
    fps = 1.0 / (sum(times) / len(times)) if times else 0
    latency = (sum(times) / len(times)) * 1000 if times else 0
    
    return {
        'name': name,
        'params': params,
        'nonzero': nonzero,
        'flops': flops,
        'fps': fps,
        'latency': latency
    }


def main():
    print("=" * 70)
    print("ğŸš€ YOLO11 ìˆ˜ë™ Structured Pruning ë²¤ì¹˜ë§ˆí¬")
    print("=" * 70)
    
    if not MODEL_PATH.exists():
        print(f"âŒ ëª¨ë¸ ì—†ìŒ: {MODEL_PATH}")
        return
    
    results = []
    
    # 1. ì›ë³¸ ëª¨ë¸
    print("\n[1] ì›ë³¸ ëª¨ë¸ ì¸¡ì •...")
    yolo_base = YOLO(MODEL_PATH)
    base_result = benchmark_model(yolo_base.model, "Baseline")
    results.append(base_result)
    print(f"   ğŸ“Š Params: {base_result['params']:.3f}M")
    print(f"   ğŸ“Š FLOPs: {base_result['flops']:.3f}G")
    print(f"   ğŸ“Š FPS: {base_result['fps']:.1f}")
    
    # 2. Pruned ëª¨ë¸ë“¤
    prune_ratios = [0.3, 0.5, 0.7]
    
    for ratio in prune_ratios:
        print(f"\n[Pruning {int(ratio*100)}%]")
        try:
            pruned_model, yolo_obj = prune_model_safe(MODEL_PATH, ratio)
            result = benchmark_model(pruned_model, f"Pruned_{int(ratio*100)}%")
            results.append(result)
            
            # ì‹¤ì œ ê°ì†Œìœ¨
            param_reduction = (1 - result['params'] / base_result['params']) * 100
            flops_reduction = (1 - result['flops'] / base_result['flops']) * 100 if base_result['flops'] > 0 else 0
            
            print(f"   ğŸ“Š Params: {result['params']:.3f}M ({param_reduction:.1f}% â†“)")
            print(f"   ğŸ“Š FLOPs: {result['flops']:.3f}G ({flops_reduction:.1f}% â†“)")
            print(f"   ğŸ“Š FPS: {result['fps']:.1f}")
            
            # ëª¨ë¸ ì €ì¥
            save_path = ROOT / f"assets/models/yolo11n_hand_pose_manual_pruned_{int(ratio*100)}.pt"
            torch.save({
                'model': pruned_model.state_dict(),
            }, save_path)
            print(f"   ğŸ’¾ ì €ì¥: {save_path.name}")
            
        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print(f"{'Model':<20} | {'Params(M)':<12} | {'FLOPs(G)':<12} | {'FPS':<10} | {'Latency(ms)':<12}")
    print("-" * 80)
    for r in results:
        print(f"{r['name']:<20} | {r['params']:<12.3f} | {r['flops']:<12.3f} | {r['fps']:<10.1f} | {r['latency']:<12.1f}")
    print("=" * 80)


if __name__ == "__main__":
    main()
