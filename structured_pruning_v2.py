"""
ğŸ”§ YOLO11 ì™„ì „í•œ Structured Pruning v2

í•µì‹¬: ê° ë ˆì´ì–´ì˜ ì¶œë ¥ ì±„ë„ì„ ì¤„ì¼ ë•Œ, 
ì—°ê²°ëœ ë‹¤ìŒ ë ˆì´ì–´ì˜ ì…ë ¥ ì±„ë„ë„ í•¨ê»˜ ì¡°ì •í•©ë‹ˆë‹¤.

YOLO11 êµ¬ì¡°:
- Backbone: Conv -> C3k2 -> Conv -> C3k2 -> ... -> SPPF -> C2PSA
- Neck: Upsample -> Concat -> C3k2 (FPN êµ¬ì¡°)
- Head: Pose (detection + keypoints)
"""

import os
import sys
import copy
import time
from pathlib import Path
from collections import OrderedDict

import torch
import torch.nn as nn
import numpy as np

from ultralytics import YOLO

# FLOPs ì¸¡ì •
try:
    from thop import profile
    HAS_THOP = True
except ImportError:
    HAS_THOP = False

# =========================================================
# ì„¤ì •
# =========================================================
ROOT = Path(__file__).resolve().parent
MODEL_PATH = ROOT / "assets/models/yolo11n_hand_pose.pt"
IMG_SIZE = 640


# =========================================================
# ì±„ë„ ì¤‘ìš”ë„ ê³„ì‚°
# =========================================================
def compute_importance(weight: torch.Tensor) -> torch.Tensor:
    """L2 norm ê¸°ë°˜ ì¤‘ìš”ë„"""
    if len(weight.shape) == 4:  # Conv: (out, in, h, w)
        return weight.abs().pow(2).sum(dim=(1, 2, 3))
    elif len(weight.shape) == 2:  # Linear: (out, in)
        return weight.abs().pow(2).sum(dim=1)
    return weight.abs()


def get_keep_mask(importance: torch.Tensor, keep_ratio: float, min_channels: int = 8) -> torch.Tensor:
    """ì¤‘ìš”ë„ ê¸°ë°˜ìœ¼ë¡œ ìœ ì§€í•  ì±„ë„ ë§ˆìŠ¤í¬ ë°˜í™˜"""
    n = len(importance)
    n_keep = max(min_channels, int(n * keep_ratio))
    n_keep = min(n_keep, n)
    
    # 8ì˜ ë°°ìˆ˜ë¡œ ë§ì¶¤
    n_keep = max(min_channels, (n_keep // 8) * 8)
    n_keep = min(n_keep, n)
    
    _, indices = torch.topk(importance, n_keep)
    mask = torch.zeros(n, dtype=torch.bool)
    mask[indices] = True
    return mask


# =========================================================
# YOLO11 êµ¬ì¡° ë¶„ì„ ë° Pruning
# =========================================================
class YOLO11Pruner:
    def __init__(self, model_path: str, prune_ratio: float = 0.3):
        self.prune_ratio = prune_ratio
        self.keep_ratio = 1.0 - prune_ratio
        
        # ëª¨ë¸ ë¡œë“œ
        self.yolo = YOLO(model_path)
        self.model = copy.deepcopy(self.yolo.model)
        self.model.eval()
        
        # ì±„ë„ ë§ˆìŠ¤í¬ ì €ì¥ì†Œ
        self.channel_masks = {}  # name -> mask tensor
        
    def analyze_structure(self):
        """YOLO11 êµ¬ì¡° ë¶„ì„"""
        print("\n=== YOLO11 êµ¬ì¡° ë¶„ì„ ===")
        
        for i, block in enumerate(self.model.model):
            block_name = type(block).__name__
            
            # ë¸”ë¡ì˜ ì¶œë ¥ ì±„ë„ í™•ì¸
            out_ch = None
            for name, m in block.named_modules():
                if isinstance(m, nn.Conv2d):
                    out_ch = m.out_channels
                elif isinstance(m, nn.BatchNorm2d):
                    out_ch = m.num_features
            
            print(f"[{i:2d}] {block_name:15} | out_ch={out_ch}")
    
    def prune_conv_bn_pair(self, conv: nn.Conv2d, bn: nn.BatchNorm2d, 
                           out_mask: torch.Tensor = None, in_mask: torch.Tensor = None):
        """Conv + BN ìŒì˜ ì±„ë„ pruning"""
        
        # ì¶œë ¥ ì±„ë„ pruning (ì´ ë ˆì´ì–´ì˜ í•„í„° ê°œìˆ˜)
        if out_mask is not None:
            keep_idx = out_mask.nonzero().squeeze(-1)
            
            conv.weight.data = conv.weight.data[keep_idx]
            conv.out_channels = len(keep_idx)
            if conv.bias is not None:
                conv.bias.data = conv.bias.data[keep_idx]
            
            bn.weight.data = bn.weight.data[keep_idx]
            bn.bias.data = bn.bias.data[keep_idx]
            bn.running_mean.data = bn.running_mean.data[keep_idx]
            bn.running_var.data = bn.running_var.data[keep_idx]
            bn.num_features = len(keep_idx)
        
        # ì…ë ¥ ì±„ë„ pruning (ì´ì „ ë ˆì´ì–´ì˜ ì¶œë ¥)
        if in_mask is not None:
            keep_idx = in_mask.nonzero().squeeze(-1)
            
            # groups ì²˜ë¦¬ (depthwise conv ë“±)
            if conv.groups == 1:
                conv.weight.data = conv.weight.data[:, keep_idx]
                conv.in_channels = len(keep_idx)
            elif conv.groups == conv.in_channels:  # Depthwise
                conv.weight.data = conv.weight.data[keep_idx]
                conv.groups = len(keep_idx)
                conv.in_channels = len(keep_idx)
                conv.out_channels = len(keep_idx)
    
    def prune_entire_model(self):
        """
        ì „ì²´ ëª¨ë¸ pruning
        
        í•µì‹¬ ì „ëµ:
        1. Backboneì˜ ê° stage ë ì±„ë„ì„ ê¸°ì¤€ìœ¼ë¡œ pruning
        2. Skip connectionê³¼ Concatì„ ê³ ë ¤í•œ ì±„ë„ ë™ê¸°í™”
        3. Detection headëŠ” ë³´ì¡´
        """
        print(f"\n{'='*60}")
        print(f"ğŸ”§ YOLO11 Structured Pruning (ratio: {self.prune_ratio*100:.0f}%)")
        print(f"{'='*60}")
        
        before_params = sum(p.numel() for p in self.model.parameters())
        print(f"Before: {before_params/1e6:.3f}M params")
        
        # YOLO11n ì±„ë„ êµ¬ì¡° (ì¸ë±ìŠ¤: ì¶œë ¥ì±„ë„)
        # Block 0: 16, Block 1: 32, Block 2(C3k2): 64
        # Block 3: 64, Block 4(C3k2): 128
        # Block 5: 128, Block 6(C3k2): 128
        # Block 7: 256, Block 8(C3k2): 256
        # Block 9(SPPF): 256, Block 10(C2PSA): 256
        
        # === ê°„ë‹¨í•œ ì ‘ê·¼: ê° Conv ë¸”ë¡ì˜ ì¶œë ¥ ì±„ë„ë§Œ pruning ===
        # (Concatê³¼ skip connection ì˜í–¥ ìµœì†Œí™”ë¥¼ ìœ„í•´ ë³´ìˆ˜ì ìœ¼ë¡œ)
        
        pruned_count = 0
        
        for name, module in self.model.named_modules():
            # Ultralytics Conv ë¸”ë¡ (Conv2d + BN + Act)
            if type(module).__name__ == 'Conv' and hasattr(module, 'conv') and hasattr(module, 'bn'):
                conv = module.conv
                bn = module.bn
                
                # ìŠ¤í‚µ ì¡°ê±´
                if conv.in_channels == 3:  # RGB ì…ë ¥
                    continue
                if conv.out_channels < 16:  # ë„ˆë¬´ ì‘ìŒ
                    continue
                
                # Detection/Pose head ìŠ¤í‚µ (ì¶œë ¥ í˜•íƒœ ìœ ì§€ í•„ìš”)
                if 'model.23' in name:  # Pose head
                    continue
                
                # ì¤‘ìš”ë„ ê³„ì‚°
                importance = compute_importance(conv.weight.data)
                out_mask = get_keep_mask(importance, self.keep_ratio)
                
                n_before = conv.out_channels
                n_after = out_mask.sum().item()
                
                if n_after < n_before:
                    keep_idx = out_mask.nonzero().squeeze(-1)
                    
                    # Conv ì¶œë ¥ ì±„ë„ pruning
                    conv.weight.data = conv.weight.data[keep_idx]
                    conv.out_channels = int(n_after)
                    if conv.bias is not None:
                        conv.bias.data = conv.bias.data[keep_idx]
                    
                    # BN ë™ê¸°í™”
                    bn.weight.data = bn.weight.data[keep_idx]
                    bn.bias.data = bn.bias.data[keep_idx]
                    bn.running_mean.data = bn.running_mean.data[keep_idx]
                    bn.running_var.data = bn.running_var.data[keep_idx]
                    bn.num_features = int(n_after)
                    
                    # ì´ ë ˆì´ì–´ì˜ ë§ˆìŠ¤í¬ ì €ì¥ (ë‹¤ìŒ ë ˆì´ì–´ ì…ë ¥ ì¡°ì •ìš©)
                    self.channel_masks[name] = out_mask
                    
                    pruned_count += 1
                    print(f"  âœ‚ï¸ {name}: {n_before} -> {n_after}")
        
        # === ë‘ ë²ˆì§¸ íŒ¨ìŠ¤: ì…ë ¥ ì±„ë„ ë™ê¸°í™” ===
        print("\n  === ì…ë ¥ ì±„ë„ ë™ê¸°í™” ===")
        
        for name, module in self.model.named_modules():
            if isinstance(module, nn.Conv2d):
                # ì´ì „ ë ˆì´ì–´ ì°¾ê¸° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
                # ì˜ˆ: model.1.convì˜ ì…ë ¥ì€ model.0ì˜ ì¶œë ¥
                
                parts = name.split('.')
                if len(parts) >= 2 and parts[0] == 'model':
                    try:
                        block_idx = int(parts[1])
                        prev_block_name = f"model.{block_idx - 1}"
                        
                        # ì´ì „ ë¸”ë¡ì˜ ë§ˆìŠ¤í¬ í™•ì¸
                        prev_mask = None
                        for mask_name, mask in self.channel_masks.items():
                            if prev_block_name in mask_name:
                                prev_mask = mask
                                break
                        
                        if prev_mask is not None and module.groups == 1:
                            # í˜„ì¬ convì˜ ì…ë ¥ ì±„ë„ê³¼ ë§ˆìŠ¤í¬ í¬ê¸° ë¹„êµ
                            if module.in_channels == len(prev_mask):
                                keep_idx = prev_mask.nonzero().squeeze(-1)
                                module.weight.data = module.weight.data[:, keep_idx]
                                module.in_channels = len(keep_idx)
                                print(f"    ğŸ”— {name} in_ch adjusted")
                    except (ValueError, IndexError):
                        pass
        
        after_params = sum(p.numel() for p in self.model.parameters())
        print(f"\nAfter: {after_params/1e6:.3f}M params")
        print(f"Reduction: {(1 - after_params/before_params)*100:.1f}%")
        
        return self.model
    
    def validate_forward(self):
        """Forward pass í…ŒìŠ¤íŠ¸"""
        try:
            dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)
            self.model.eval()
            with torch.no_grad():
                output = self.model(dummy)
            print("âœ… Forward pass ì„±ê³µ!")
            return True
        except Exception as e:
            print(f"âŒ Forward pass ì‹¤íŒ¨: {e}")
            return False
    
    def get_metrics(self):
        """ëª¨ë¸ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        params = sum(p.numel() for p in self.model.parameters()) / 1e6
        
        flops = 0.0
        if HAS_THOP:
            try:
                dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)
                macs, _ = profile(self.model, inputs=(dummy,), verbose=False)
                flops = macs / 1e9
                
                for m in self.model.modules():
                    for attr in ['total_ops', 'total_params']:
                        if hasattr(m, attr):
                            delattr(m, attr)
            except:
                pass
        
        return params, flops


# =========================================================
# ë” ì•ˆì „í•œ ë°©ë²•: Width Multiplier Scaling
# =========================================================
def create_smaller_yolo(model_path: str, width_mult: float = 0.5):
    """
    YOLO ëª¨ë¸ì˜ width multiplierë¥¼ ì¤„ì—¬ì„œ ë” ì‘ì€ ëª¨ë¸ ìƒì„±
    
    ì´ ë°©ë²•ì€ ì±„ë„ ìˆ˜ë¥¼ ê· ì¼í•˜ê²Œ ì¤„ì´ë¯€ë¡œ ì˜ì¡´ì„± ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.
    """
    print(f"\n{'='*60}")
    print(f"ğŸ”§ Width Multiplier Scaling (mult: {width_mult})")
    print(f"{'='*60}")
    
    yolo = YOLO(model_path)
    model = yolo.model
    model.eval()
    
    before_params = sum(p.numel() for p in model.parameters())
    print(f"Before: {before_params/1e6:.3f}M params")
    
    # ëª¨ë“  Conv + BN ìŒì˜ ì±„ë„ì„ width_mult ë¹„ìœ¨ë¡œ ì¤„ì„
    for name, module in model.named_modules():
        if type(module).__name__ == 'Conv' and hasattr(module, 'conv') and hasattr(module, 'bn'):
            conv = module.conv
            bn = module.bn
            
            # ì…ë ¥ ì±„ë„ 3 (RGB) ë˜ëŠ” ì¶œë ¥ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ìŠ¤í‚µ
            if conv.in_channels == 3 or conv.out_channels <= 8:
                continue
            
            # Pose head ìŠ¤í‚µ
            if 'model.23' in name:
                continue
            
            # ìƒˆ ì±„ë„ ìˆ˜ ê³„ì‚° (8ì˜ ë°°ìˆ˜)
            new_out = max(8, int(conv.out_channels * width_mult) // 8 * 8)
            
            if new_out < conv.out_channels:
                # ê°€ì¥ ì¤‘ìš”í•œ ì±„ë„ë§Œ ìœ ì§€
                importance = compute_importance(conv.weight.data)
                _, keep_idx = torch.topk(importance, new_out)
                keep_idx = keep_idx.sort().values
                
                # ì¶œë ¥ ì±„ë„ pruning
                conv.weight.data = conv.weight.data[keep_idx]
                conv.out_channels = new_out
                if conv.bias is not None:
                    conv.bias.data = conv.bias.data[keep_idx]
                
                # BN ë™ê¸°í™”
                bn.weight.data = bn.weight.data[keep_idx]
                bn.bias.data = bn.bias.data[keep_idx]
                bn.running_mean.data = bn.running_mean.data[keep_idx]
                bn.running_var.data = bn.running_var.data[keep_idx]
                bn.num_features = new_out
    
    after_params = sum(p.numel() for p in model.parameters())
    print(f"After: {after_params/1e6:.3f}M params")
    print(f"Reduction: {(1 - after_params/before_params)*100:.1f}%")
    
    return model


# =========================================================
# Unstructured Pruning (í™•ì‹¤í•˜ê²Œ ë™ì‘) + Sparsity ì¸¡ì •
# =========================================================
def apply_unstructured_pruning(model_path: str, prune_ratio: float = 0.3):
    """
    Unstructured pruning ì ìš©
    - íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ë™ì¼
    - Non-zero íŒŒë¼ë¯¸í„° ë¹„ìœ¨ ê°ì†Œ
    - ëª¨ë¸ì€ ì •ìƒ ë™ì‘
    """
    print(f"\n{'='*60}")
    print(f"ğŸ”§ Unstructured Pruning (ratio: {prune_ratio*100:.0f}%)")
    print(f"{'='*60}")
    
    import torch.nn.utils.prune as prune
    
    yolo = YOLO(model_path)
    model = yolo.model
    model.eval()
    
    total_params = sum(p.numel() for p in model.parameters())
    nonzero_before = sum((p != 0).sum().item() for p in model.parameters())
    
    print(f"Before: {total_params/1e6:.3f}M params, {nonzero_before/1e6:.3f}M non-zero")
    
    # L1 unstructured pruning ì ìš©
    for name, module in model.named_modules():
        if isinstance(module, nn.Conv2d):
            prune.l1_unstructured(module, name='weight', amount=prune_ratio)
            prune.remove(module, 'weight')
    
    nonzero_after = sum((p != 0).sum().item() for p in model.parameters())
    
    print(f"After: {total_params/1e6:.3f}M params, {nonzero_after/1e6:.3f}M non-zero")
    print(f"Sparsity: {(1 - nonzero_after/nonzero_before)*100:.1f}%")
    
    return model, yolo


# =========================================================
# ë²¤ì¹˜ë§ˆí¬
# =========================================================
def benchmark(model, name: str, device='cpu'):
    """ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì •"""
    model = model.to(device).eval()
    
    params = sum(p.numel() for p in model.parameters()) / 1e6
    nonzero = sum((p != 0).sum().item() for p in model.parameters()) / 1e6
    
    flops = 0.0
    if HAS_THOP:
        try:
            dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)
            macs, _ = profile(model, inputs=(dummy,), verbose=False)
            flops = macs / 1e9
            for m in model.modules():
                for attr in ['total_ops', 'total_params']:
                    if hasattr(m, attr):
                        delattr(m, attr)
        except Exception as e:
            print(f"  âš ï¸ FLOPs ì¸¡ì • ì‹¤íŒ¨: {str(e)[:50]}")
    
    # ì†ë„ ì¸¡ì •
    dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)
    fps, latency = 0.0, 0.0
    
    try:
        # Warmup
        with torch.no_grad():
            for _ in range(5):
                model(dummy)
        
        # Measure
        times = []
        with torch.no_grad():
            for _ in range(20):
                t0 = time.time()
                model(dummy)
                times.append(time.time() - t0)
        
        fps = 1.0 / (sum(times) / len(times))
        latency = (sum(times) / len(times)) * 1000
    except Exception as e:
        print(f"  âš ï¸ ì†ë„ ì¸¡ì • ì‹¤íŒ¨: {str(e)[:50]}")
    
    return {
        'name': name,
        'params': params,
        'nonzero': nonzero,
        'flops': flops,
        'fps': fps,
        'latency': latency
    }


def main():
    print("=" * 70)
    print("ğŸš€ YOLO11 Structured Pruning ë²¤ì¹˜ë§ˆí¬ v2")
    print("=" * 70)
    
    if not MODEL_PATH.exists():
        print(f"âŒ ëª¨ë¸ ì—†ìŒ: {MODEL_PATH}")
        return
    
    results = []
    
    # 1. ì›ë³¸ ëª¨ë¸
    print("\n[1] ì›ë³¸ ëª¨ë¸ ì¸¡ì •...")
    yolo_base = YOLO(MODEL_PATH)
    base_result = benchmark(yolo_base.model, "Baseline")
    results.append(base_result)
    print(f"   Params: {base_result['params']:.3f}M, FLOPs: {base_result['flops']:.3f}G, FPS: {base_result['fps']:.1f}")
    
    # 2. Unstructured Pruning (í™•ì‹¤í•˜ê²Œ ë™ì‘)
    print("\n[2] Unstructured Pruning...")
    for ratio in [0.3, 0.5, 0.7]:
        model, yolo = apply_unstructured_pruning(MODEL_PATH, ratio)
        result = benchmark(model, f"Unstructured_{int(ratio*100)}%")
        result['sparsity'] = ratio
        results.append(result)
        
        # ì €ì¥
        save_path = ROOT / f"assets/models/yolo11n_unstructured_{int(ratio*100)}.pt"
        yolo.save(str(save_path))
        print(f"   ğŸ’¾ ì €ì¥: {save_path.name}")
    
    # 3. Width Multiplier Scaling (êµ¬ì¡°ì  ë³€ê²½, ë™ì‘ ê°€ëŠ¥)
    print("\n[3] Width Multiplier Scaling...")
    for mult in [0.75, 0.5, 0.25]:
        try:
            model = create_smaller_yolo(MODEL_PATH, mult)
            
            # Forward í…ŒìŠ¤íŠ¸
            dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)
            try:
                with torch.no_grad():
                    output = model(dummy)
                print(f"   âœ… Width {mult} forward ì„±ê³µ")
                
                result = benchmark(model, f"Width_{mult}")
                results.append(result)
                
                # ì €ì¥
                save_path = ROOT / f"assets/models/yolo11n_width_{int(mult*100)}.pt"
                torch.save({'model': model.state_dict()}, save_path)
                
            except Exception as e:
                print(f"   âŒ Width {mult} forward ì‹¤íŒ¨: {str(e)[:50]}")
        except Exception as e:
            print(f"   âŒ Width {mult} ìƒì„± ì‹¤íŒ¨: {str(e)[:50]}")
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 90)
    print(f"{'Model':<25} | {'Params(M)':<12} | {'NonZero(M)':<12} | {'FLOPs(G)':<10} | {'FPS':<8}")
    print("-" * 90)
    for r in results:
        print(f"{r['name']:<25} | {r['params']:<12.3f} | {r['nonzero']:<12.3f} | {r['flops']:<10.3f} | {r['fps']:<8.1f}")
    print("=" * 90)


if __name__ == "__main__":
    main()
