"""
ğŸ“Š ëª¨ë¸ ìµœì í™” ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸ (ìˆ˜ì •ë³¸)

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ 3ê°€ì§€ë¥¼ ì •í™•í•˜ê²Œ ì¸¡ì •í•©ë‹ˆë‹¤:
1. ëª¨ë¸ ì‚¬ì´ì¦ˆ (íŒŒë¼ë¯¸í„° ìˆ˜)
2. FLOPs (ì—°ì‚°ëŸ‰)
3. ì‹¤í–‰ ì†ë„ (FPS/Latency)

âš ï¸ Jetson Nanoì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”!
"""

import os
import sys
import time
import csv
import copy
from pathlib import Path

import torch
import torch.nn as nn
import numpy as np

# =========================================================
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
# =========================================================
try:
    from ultralytics import YOLO
except ImportError:
    print("âŒ 'ultralytics' ì„¤ì¹˜ í•„ìš”: pip install ultralytics")
    sys.exit(1)

# torch_pruning í™•ì¸ (ì§„ì§œ structured pruningìš©)
try:
    import torch_pruning as tp
    HAS_TP = True
except ImportError:
    HAS_TP = False
    print("âš ï¸ 'torch_pruning' ì—†ìŒ. Structured pruning ê±´ë„ˆëœ€")
    print("   ì„¤ì¹˜: pip install torch-pruning")

# FLOPs ê³„ì‚°ë„êµ¬
try:
    from thop import profile
    HAS_THOP = True
except ImportError:
    HAS_THOP = False
    print("âš ï¸ 'thop' ì—†ìŒ. FLOPs ê³„ì‚° ê±´ë„ˆëœ€")
    print("   ì„¤ì¹˜: pip install thop")

# =========================================================
# âš™ï¸ ì„¤ì •
# =========================================================
ROOT_DIR = Path(__file__).resolve().parent
ASSETS_DIR = ROOT_DIR / "assets"
MODELS_DIR = ASSETS_DIR / "models"
ORIGINAL_MODEL_PATH = MODELS_DIR / "yolo11n_hand_pose.pt"

IMG_SIZE = 640
RESULTS_FILE = ROOT_DIR / "benchmark_results.csv"

# Jetson Nano í™˜ê²½ ê°ì§€
IS_JETSON = os.path.exists("/etc/nv_tegra_release")
if IS_JETSON:
    print("âœ… Jetson Nano í™˜ê²½ ê°ì§€ë¨")
    DEVICE = 0  # GPU
else:
    print("â„¹ï¸ ì¼ë°˜ PC í™˜ê²½ (CPU ëª¨ë“œ)")
    DEVICE = 'cpu'

# =========================================================
# ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =========================================================

def count_parameters(model: nn.Module) -> int:
    """ëª¨ë¸ì˜ ì´ íŒŒë¼ë¯¸í„° ìˆ˜(í•™ìŠµê°€ëŠ¥+ê³ ì •) ë°˜í™˜"""
    return sum(p.numel() for p in model.parameters())


def count_nonzero_parameters(model: nn.Module) -> int:
    """0ì´ ì•„ë‹Œ íŒŒë¼ë¯¸í„° ìˆ˜ë§Œ ê³„ì‚°"""
    return sum((p != 0).sum().item() for p in model.parameters())


def get_flops(model: nn.Module, input_size=(1, 3, 640, 640)) -> float:
    """FLOPs(GFLOPs) ë°˜í™˜"""
    if not HAS_THOP:
        return 0.0
    
    model = model.to('cpu').eval()
    dummy_input = torch.randn(input_size).to('cpu')
    
    try:
        macs, _ = profile(model, inputs=(dummy_input,), verbose=False)
        # thopì´ ìƒì„±í•œ ì„ì‹œ ì†ì„± ì œê±°
        for module in model.modules():
            for attr in ['total_ops', 'total_params']:
                if hasattr(module, attr):
                    delattr(module, attr)
        return macs / 1e9  # GFLOPs
    except Exception as e:
        print(f"   âš ï¸ FLOPs ì¸¡ì • ì‹¤íŒ¨: {e}")
        return 0.0


def get_model_size_mb(file_path) -> float:
    """íŒŒì¼ í¬ê¸°(MB) ë°˜í™˜"""
    if not os.path.exists(file_path):
        return 0.0
    if os.path.isdir(file_path):
        return sum(
            os.path.getsize(os.path.join(dp, f)) 
            for dp, _, fn in os.walk(file_path) for f in fn
        ) / (1024**2)
    return os.path.getsize(file_path) / (1024**2)


def measure_speed(model, num_warmup=10, num_test=50) -> tuple:
    """
    ì¶”ë¡  ì†ë„ ì¸¡ì •
    Returns: (avg_fps, avg_latency_ms)
    """
    dummy_img = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
    
    # Warmup
    for _ in range(num_warmup):
        model.predict(dummy_img, imgsz=IMG_SIZE, verbose=False, device=DEVICE)
    
    # Measure
    times = []
    for _ in range(num_test):
        t_start = time.time()
        model.predict(dummy_img, imgsz=IMG_SIZE, verbose=False, device=DEVICE)
        t_end = time.time()
        times.append(t_end - t_start)
    
    avg_time = sum(times) / len(times)
    avg_fps = 1.0 / avg_time
    avg_latency_ms = avg_time * 1000
    
    return avg_fps, avg_latency_ms


def save_results(results: list):
    """ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥"""
    with open(RESULTS_FILE, 'w', newline='', encoding='utf-8') as f:
        fieldnames = ['Model', 'Type', 'Params(M)', 'NonZero_Params(M)', 'FLOPs(G)', 
                      'FPS', 'Latency(ms)', 'Size(MB)', 'Prune_Rate', 'Precision']
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for row in results:
            writer.writerow(row)
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {RESULTS_FILE}")


# =========================================================
# ğŸ¯ Structured Pruning í•¨ìˆ˜ (ì§„ì§œ ì±„ë„ ì œê±°)
# =========================================================

def apply_structured_pruning(model: nn.Module, prune_rate: float) -> nn.Module:
    """
    torch_pruningì„ ì‚¬ìš©í•œ ì§„ì§œ Structured Pruning
    ì‹¤ì œë¡œ ì±„ë„ ìˆ˜ë¥¼ ì¤„ì—¬ì„œ íŒŒë¼ë¯¸í„°ì™€ FLOPs ê°ì†Œ
    """
    if not HAS_TP:
        return model
    
    model = model.to('cpu').eval()
    example_inputs = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to('cpu')
    
    # YOLO ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´ ê°ì§€ (pruningì—ì„œ ì œì™¸)
    ignored_layers = []
    
    # Detect2D, Pose, Segment ë“±ì˜ head ë ˆì´ì–´ ìë™ ê°ì§€
    for name, module in model.named_modules():
        # YOLO headì˜ ë§ˆì§€ë§‰ Conv ë ˆì´ì–´ë“¤ì€ ì¶œë ¥ ì±„ë„ì´ ê³ ì •ë˜ì–´ì•¼ í•¨
        if 'cv2' in name or 'cv3' in name:  # Detection head
            ignored_layers.append(module)
        if 'cv4' in name:  # Pose head
            ignored_layers.append(module)
        # DFL(Distribution Focal Loss) ë ˆì´ì–´ë„ ì œì™¸
        if hasattr(module, 'reg_max'):
            ignored_layers.append(module)
    
    # Importance ê³„ì‚°ê¸° (L1 magnitude ê¸°ë°˜)
    imp = tp.importance.MagnitudeImportance(p=1)
    
    # Pruner ìƒì„± - DepGraph ê¸°ë°˜ìœ¼ë¡œ ì˜ì¡´ì„± ìë™ ì²˜ë¦¬
    pruner = tp.pruner.MagnitudePruner(
        model,
        example_inputs,
        importance=imp,
        iterative_steps=1,
        pruning_ratio=prune_rate,
        ignored_layers=ignored_layers,
        unwrapped_parameters=None,
        round_to=8,  # ì±„ë„ ìˆ˜ë¥¼ 8ì˜ ë°°ìˆ˜ë¡œ ë§ì¶¤ (GPU íš¨ìœ¨)
    )
    
    # Pruning ì‹¤í–‰
    pruner.step()
    
    return model


# =========================================================
# ğŸ¯ ë©”ì¸ ë²¤ì¹˜ë§ˆí¬
# =========================================================

def run_benchmark():
    print("=" * 70)
    print("ğŸš€ ëª¨ë¸ ìµœì í™” ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    print("=" * 70)
    
    if not ORIGINAL_MODEL_PATH.exists():
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {ORIGINAL_MODEL_PATH}")
        return
    
    results = []
    
    # =========================================================
    # 1ï¸âƒ£ ì›ë³¸ ëª¨ë¸ (Baseline)
    # =========================================================
    print("\n[1] ì›ë³¸ ëª¨ë¸ (Baseline) ì¸¡ì •...")
    
    yolo_base = YOLO(ORIGINAL_MODEL_PATH)
    model_base = yolo_base.model
    
    base_params = count_parameters(model_base) / 1e6
    base_nonzero = count_nonzero_parameters(model_base) / 1e6
    base_flops = get_flops(model_base)
    base_fps, base_latency = measure_speed(yolo_base)
    base_size = get_model_size_mb(ORIGINAL_MODEL_PATH)
    
    print(f"   ğŸ“Š íŒŒë¼ë¯¸í„°: {base_params:.3f}M")
    print(f"   ğŸ“Š FLOPs: {base_flops:.3f}G")
    print(f"   ğŸ“Š ì†ë„: {base_fps:.1f} FPS ({base_latency:.1f}ms)")
    print(f"   ğŸ“Š í¬ê¸°: {base_size:.2f}MB")
    
    results.append({
        'Model': 'Baseline',
        'Type': 'Original',
        'Params(M)': round(base_params, 3),
        'NonZero_Params(M)': round(base_nonzero, 3),
        'FLOPs(G)': round(base_flops, 3),
        'FPS': round(base_fps, 1),
        'Latency(ms)': round(base_latency, 1),
        'Size(MB)': round(base_size, 2),
        'Prune_Rate': 0.0,
        'Precision': 'FP32'
    })
    
    # =========================================================
    # 2ï¸âƒ£ Structured Pruning (30%, 50%, 70%)
    # =========================================================
    if HAS_TP:
        print("\n[2] Structured Pruning ëª¨ë¸ ìƒì„± ë° ì¸¡ì •...")
        
        prune_rates = [0.3, 0.5, 0.7]
        
        for rate in prune_rates:
            pct = int(rate * 100)
            print(f"\n   ğŸ”¹ Pruning Rate: {pct}%")
            
            try:
                # ìƒˆë¡œìš´ ëª¨ë¸ ë¡œë“œ (ë§¤ë²ˆ freshí•˜ê²Œ)
                yolo_tmp = YOLO(ORIGINAL_MODEL_PATH)
                model_pruned = copy.deepcopy(yolo_tmp.model)
                
                # Structured Pruning ì ìš©
                model_pruned = apply_structured_pruning(model_pruned, rate)
                
                # ì¸¡ì •
                pruned_params = count_parameters(model_pruned) / 1e6
                pruned_nonzero = count_nonzero_parameters(model_pruned) / 1e6
                pruned_flops = get_flops(model_pruned)
                
                # ì €ì¥ í›„ YOLOë¡œ ë‹¤ì‹œ ë¡œë“œí•˜ì—¬ ì†ë„ ì¸¡ì •
                save_path = MODELS_DIR / f"yolo11n_hand_pose_real_pruned_{pct}.pt"
                
                # state_dictë§Œ ì €ì¥ (ì „ì²´ ëª¨ë¸ ì €ì¥ë³´ë‹¤ ì•ˆì „)
                torch.save({
                    'model': model_pruned.state_dict(),
                    'yaml': yolo_tmp.model.yaml,  # êµ¬ì¡° ì •ë³´
                    'stride': yolo_tmp.model.stride,
                    'names': yolo_tmp.model.names,
                }, save_path)
                
                pruned_size = get_model_size_mb(save_path)
                
                # ì†ë„ ì¸¡ì • (raw PyTorch ëª¨ë¸ë¡œ)
                model_pruned.to(DEVICE if DEVICE != 'cpu' else 'cpu').eval()
                
                dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)
                if DEVICE != 'cpu':
                    dummy_input = dummy_input.cuda()
                
                # Warmup
                for _ in range(10):
                    with torch.no_grad():
                        model_pruned(dummy_input)
                
                # Measure
                times = []
                for _ in range(50):
                    t_start = time.time()
                    with torch.no_grad():
                        model_pruned(dummy_input)
                    times.append(time.time() - t_start)
                
                pruned_fps = 1.0 / (sum(times) / len(times))
                pruned_latency = (sum(times) / len(times)) * 1000
                
                # ì‹¤ì œ ê°ì†Œìœ¨ ê³„ì‚°
                param_reduction = (1 - pruned_params / base_params) * 100
                flops_reduction = (1 - pruned_flops / base_flops) * 100 if base_flops > 0 else 0
                
                print(f"      âœ… íŒŒë¼ë¯¸í„°: {pruned_params:.3f}M ({param_reduction:.1f}% ê°ì†Œ)")
                print(f"      âœ… FLOPs: {pruned_flops:.3f}G ({flops_reduction:.1f}% ê°ì†Œ)")
                print(f"      âœ… ì†ë„: {pruned_fps:.1f} FPS ({pruned_latency:.1f}ms)")
                print(f"      âœ… í¬ê¸°: {pruned_size:.2f}MB")
                
                results.append({
                    'Model': f'Pruned_{pct}%',
                    'Type': 'Structured_Pruning',
                    'Params(M)': round(pruned_params, 3),
                    'NonZero_Params(M)': round(pruned_nonzero, 3),
                    'FLOPs(G)': round(pruned_flops, 3),
                    'FPS': round(pruned_fps, 1),
                    'Latency(ms)': round(pruned_latency, 1),
                    'Size(MB)': round(pruned_size, 2),
                    'Prune_Rate': rate,
                    'Precision': 'FP32'
                })
                
            except Exception as e:
                print(f"      âŒ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
    
    # =========================================================
    # 3ï¸âƒ£ Quantization (FP16/INT8) - Jetsonì—ì„œë§Œ
    # =========================================================
    if IS_JETSON:
        print("\n[3] Quantization ëª¨ë¸ ìƒì„± ë° ì¸¡ì • (Jetson Only)...")
        
        # FP16 TensorRT
        print("\n   ğŸ”¹ FP16 TensorRT ë³€í™˜...")
        try:
            fp16_engine = MODELS_DIR / "yolo11n_hand_pose_fp16.engine"
            
            if not fp16_engine.exists():
                yolo_base.export(format='engine', half=True, imgsz=IMG_SIZE, device=0)
                # ìƒì„±ëœ .engine íŒŒì¼ ì´ë¦„ ë³€ê²½
                default_engine = ORIGINAL_MODEL_PATH.with_suffix('.engine')
                if default_engine.exists():
                    default_engine.rename(fp16_engine)
            
            if fp16_engine.exists():
                yolo_fp16 = YOLO(fp16_engine, task='pose')
                fp16_fps, fp16_latency = measure_speed(yolo_fp16)
                fp16_size = get_model_size_mb(fp16_engine)
                
                print(f"      âœ… FP16 ì†ë„: {fp16_fps:.1f} FPS ({fp16_latency:.1f}ms)")
                
                results.append({
                    'Model': 'TensorRT_FP16',
                    'Type': 'Quantization',
                    'Params(M)': round(base_params, 3),
                    'NonZero_Params(M)': round(base_nonzero, 3),
                    'FLOPs(G)': round(base_flops, 3),
                    'FPS': round(fp16_fps, 1),
                    'Latency(ms)': round(fp16_latency, 1),
                    'Size(MB)': round(fp16_size, 2),
                    'Prune_Rate': 0.0,
                    'Precision': 'FP16'
                })
        except Exception as e:
            print(f"      âŒ FP16 ì‹¤íŒ¨: {e}")
        
        # INT8 TensorRT
        print("\n   ğŸ”¹ INT8 TensorRT ë³€í™˜...")
        try:
            int8_engine = MODELS_DIR / "yolo11n_hand_pose_int8.engine"
            
            if not int8_engine.exists():
                yolo_base.export(format='engine', int8=True, imgsz=IMG_SIZE, device=0)
                default_engine = ORIGINAL_MODEL_PATH.with_suffix('.engine')
                if default_engine.exists():
                    default_engine.rename(int8_engine)
            
            if int8_engine.exists():
                yolo_int8 = YOLO(int8_engine, task='pose')
                int8_fps, int8_latency = measure_speed(yolo_int8)
                int8_size = get_model_size_mb(int8_engine)
                
                print(f"      âœ… INT8 ì†ë„: {int8_fps:.1f} FPS ({int8_latency:.1f}ms)")
                
                results.append({
                    'Model': 'TensorRT_INT8',
                    'Type': 'Quantization',
                    'Params(M)': round(base_params, 3),
                    'NonZero_Params(M)': round(base_nonzero, 3),
                    'FLOPs(G)': round(base_flops, 3),
                    'FPS': round(int8_fps, 1),
                    'Latency(ms)': round(int8_latency, 1),
                    'Size(MB)': round(int8_size, 2),
                    'Prune_Rate': 0.0,
                    'Precision': 'INT8'
                })
        except Exception as e:
            print(f"      âŒ INT8 ì‹¤íŒ¨: {e}")
    else:
        print("\n[3] Quantization ìŠ¤í‚µ (Jetson Nanoì—ì„œë§Œ TensorRT ì§€ì›)")
    
    # =========================================================
    # ğŸ“Š ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
    # =========================================================
    save_results(results)
    
    print("\n" + "=" * 90)
    print(f"{'Model':<20} | {'Params(M)':<12} | {'FLOPs(G)':<10} | {'FPS':<8} | {'Latency(ms)':<12} | {'Size(MB)':<10}")
    print("-" * 90)
    for r in results:
        print(f"{r['Model']:<20} | {r['Params(M)']:<12} | {r['FLOPs(G)']:<10} | {r['FPS']:<8} | {r['Latency(ms)']:<12} | {r['Size(MB)']:<10}")
    print("=" * 90)
    
    print("\nğŸ‰ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")


if __name__ == "__main__":
    run_benchmark()
