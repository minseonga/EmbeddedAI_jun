import os
import sys
import time
import torch
import torch.nn as nn
import torch.nn.utils.prune as prune
import numpy as np
from ultralytics import YOLO

# torch_pruning í™•ì¸
try:
    import torch_pruning as tp
    HAS_TP = True
except ImportError:
    HAS_TP = False
    print("âš ï¸ 'torch_pruning' ì—†ìŒ. (ì„¤ì¹˜: pip install torch-pruning)")

# =========================================================
# âš™ï¸ ì„¤ì •
# =========================================================
BASE_DIR = "assets/models"
ORIGINAL_MODEL = "yolo11n_hand_pose.pt"
IMG_SIZE = 640

# ê²½ë¡œ ì„¤ì •
original_path = os.path.join(BASE_DIR, ORIGINAL_MODEL)

print("="*70)
print("ğŸš€ [Absolute Final] ë°ì´í„°ì…‹ ì—ëŸ¬ ì—†ëŠ” ì†ë„ ì¸¡ì • ìŠ¤í¬ë¦½íŠ¸")
print("="*70)

results = []

# ---------------------------------------------------------
# ğŸ› ï¸ í—¬í¼ í•¨ìˆ˜: ì†ë„ ë° ìš©ëŸ‰ ì¸¡ì • (Predict ëª¨ë“œ)
# ---------------------------------------------------------
def benchmark_speed(model_obj, name, file_path=None, is_yolo=True):
    print(f"   ğŸ‘‰ ì¸¡ì • ì¤‘: {name}...")
    
    # 1. ìš©ëŸ‰ ì¸¡ì •
    size_mb = 0
    if file_path and os.path.exists(file_path):
        if os.path.isdir(file_path): # CoreML ë“±
            size_mb = sum(os.path.getsize(os.path.join(dp, f)) for dp, _, fn in os.walk(file_path) for f in fn) / (1024**2)
        else:
            size_mb = os.path.getsize(file_path) / (1024**2)
    
    # 2. ì†ë„ ì¸¡ì • (Warmup + Test)
    try:
        # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (ê²€ì€ í™”ë©´)
        dummy_img = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
        
        # Warmup
        for _ in range(5):
            if is_yolo:
                # verbose=Falseë¡œ ë¡œê·¸ ë„ê¸°
                model_obj.predict(dummy_img, imgsz=IMG_SIZE, verbose=False, device='cpu')
            else:
                # Raw PyTorch Model
                dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)
                model_obj(dummy_input)

        # ì§„ì§œ ì¸¡ì • (10íšŒ í‰ê· )
        t_start = time.time()
        for _ in range(10):
            if is_yolo:
                model_obj.predict(dummy_img, imgsz=IMG_SIZE, verbose=False, device='cpu')
            else:
                dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)
                with torch.no_grad():
                    model_obj(dummy_input)
        t_end = time.time()
        
        avg_time = (t_end - t_start) / 10
        fps = 1.0 / avg_time
        
        print(f"      âœ… ê²°ê³¼: {fps:.1f} FPS | {size_mb:.2f} MB")
        results.append((name, f"{fps:.1f} FPS", f"{size_mb:.2f} MB"))
        
    except Exception as e:
        print(f"      âŒ ì¸¡ì • ì‹¤íŒ¨: {str(e)[:50]}")
        results.append((name, "Error", f"{size_mb:.2f} MB"))

# =========================================================
# 1ï¸âƒ£ Original Model
# =========================================================
if os.path.exists(original_path):
    model = YOLO(original_path)
    benchmark_speed(model, "Original (FP32)", original_path)

# =========================================================
# 2ï¸âƒ£ Structured Pruning (In-Memory ì¸¡ì •)
# =========================================================
if HAS_TP and os.path.exists(original_path):
    print("\n[Step 2] Structured Pruning (30%) ìƒì„± ë° ì¸¡ì •...")
    try:
        # ëª¨ë¸ ë¡œë“œ (Raw PyTorch)
        yolo_tmp = YOLO(original_path)
        model_raw = yolo_tmp.model
        
        # Pruning
        example_inputs = torch.randn(1, 3, 640, 640)
        imp = tp.importance.MagnitudeImportance(p=1)
        ignored_layers = []
        for m in model_raw.modules():
            if isinstance(m, torch.nn.Linear) and m.out_features == model_raw.head.nc:
                ignored_layers.append(m)
        
        pruner = tp.pruner.MagnitudePruner(
            model_raw, example_inputs, importance=imp, iterative_steps=1, pruning_ratio=0.3, ignored_layers=ignored_layers
        )
        pruner.step()
        
        # ì €ì¥ (Jetsonìš©)
        save_path = original_path.replace(".pt", "_structured.pt")
        torch.save(model_raw, save_path)
        
        # ì¸¡ì • (Raw Modelë¡œ ì¸¡ì •)
        benchmark_speed(model_raw, "Structured Pruned (30%)", save_path, is_yolo=False)
        
    except Exception as e:
        print(f"   âŒ Pruning ì‹¤íŒ¨: {e}")

# =========================================================
# 3ï¸âƒ£ Unstructured Pruning (Fix & Measure)
# =========================================================
print("\n[Step 3] Unstructured Pruning ëª¨ë¸ ì •ë¦¬...")
pruned_files = [
    os.path.join(BASE_DIR, f) for f in os.listdir(BASE_DIR) 
    if f.endswith('.pt') and 'pruned' in f and 'fixed' not in f and 'structured' not in f
]

for f_path in pruned_files:
    try:
        model_wrap = YOLO(f_path)
        # ë§ˆìŠ¤í¬ ì œê±°
        for name, m in model_wrap.model.named_modules():
            if hasattr(m, "weight_mask"):
                prune.remove(m, "weight")
        
        # _fixed.ptë¡œ ì €ì¥
        fixed_path = f_path.replace(".pt", "_fixed.pt")
        model_wrap.save(fixed_path)
        
        # ì¸¡ì •
        name = os.path.basename(f_path).replace("yolo11n_hand_pose_", "").replace(".pt", "")
        benchmark_speed(YOLO(fixed_path), f"Unstructured ({name})", fixed_path)
        
    except Exception as e:
        print(f"   Skip {os.path.basename(f_path)}: {e}")

# =========================================================
# 4ï¸âƒ£ Quantization (CoreML, TFLite)
# =========================================================
print("\n[Step 4] Quantization ëª¨ë¸ ì¸¡ì •...")

# CoreML
coreml_path = original_path.replace(".pt", ".mlpackage")
if not os.path.exists(coreml_path):
    try:
        YOLO(original_path).export(format='coreml', int8=True, nms=True)
    except: pass

if os.path.exists(coreml_path):
    # CoreML ë¡œë“œëŠ” YOLO('file.mlpackage')ë¡œ ê°€ëŠ¥
    benchmark_speed(YOLO(coreml_path, task='pose'), "CoreML (INT8)", coreml_path)

# TFLite
tflite_path = None
potential_path = os.path.join(BASE_DIR, "yolo11n_hand_pose_saved_model", "yolo11n_hand_pose_int8.tflite")
if os.path.exists(potential_path):
    tflite_path = potential_path
else:
    # ì—†ìœ¼ë©´ ë§Œë“¤ì–´ì„œ ì°¾ê¸°
    try:
        YOLO(original_path).export(format='tflite', int8=True)
        if os.path.exists(potential_path): tflite_path = potential_path
    except: pass

if tflite_path:
    benchmark_speed(YOLO(tflite_path, task='pose'), "TFLite (INT8)", tflite_path)


# =========================================================
# ğŸ“Š ìµœì¢… ê²°ê³¼
# =========================================================
print("\n" + "="*75)
print(f"{'Model':<35} | {'Speed (Mac)':<15} | {'Size':<10}")
print("-" * 75)
for name, speed, size in results:
    print(f"{name:<35} | {speed:<15} | {size:<10}")
print("="*75)