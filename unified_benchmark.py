import os
import sys
import time
import csv
from pathlib import Path

import torch
import torch.nn as nn
import torch.nn.utils.prune as prune
from ultralytics import YOLO
import numpy as np

# torch_pruning í™•ì¸ ë° ì„¤ì¹˜ ì•ˆë‚´
try:
    import torch_pruning as tp
    HAS_TP = True
except ImportError:
    HAS_TP = False
    print("âš ï¸ 'torch_pruning' ì—†ìŒ. ê°€ì§€ì¹˜ê¸° ì¸¡ì •ì€ ê±´ë„ˆëœë‹ˆë‹¤. (ì„¤ì¹˜: pip install torch-pruning)")

# FLOPs ê³„ì‚° ë„êµ¬
try:
    from thop import profile
except ImportError:
    print("âš ï¸ 'thop' ì—†ìŒ. FLOPs ê³„ì‚°ì„ ê±´ë„ˆëœë‹ˆë‹¤. (ì„¤ì¹˜: pip install thop)")
    sys.exit(1) # í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë¯€ë¡œ ì¢…ë£Œ

# =========================================================
# âš™ï¸ ê²½ë¡œ ë° ì„¤ì •
# =========================================================
# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ê°€ ì‹¤í–‰ë˜ëŠ” ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
ROOT_DIR = Path(__file__).resolve().parent # /workspace/EmbeddedAI/ ê°€ì •
ASSETS_DIR = ROOT_DIR / "assets"
MODELS_DIR = ASSETS_DIR / "models"
ORIGINAL_MODEL_NAME = "yolo11n_hand_pose.pt"
ORIGINAL_MODEL_PATH = MODELS_DIR / ORIGINAL_MODEL_NAME

IMG_SIZE = 640
RESULTS_FILE = "final_experiment_results.csv"

# =========================================================
# ğŸ› ï¸ í—¬í¼ í•¨ìˆ˜
# =========================================================

def cleanup_thop_attributes(model: nn.Module):
    """thop ì¸¡ì • í›„ ëª¨ë¸ì— ë‚¨ì•„ìˆëŠ” ì„ì‹œ ì†ì„±ì„ ì œê±°í•©ë‹ˆë‹¤."""
    for module in model.modules():
        for attr in ['total_ops', 'total_params', 'n_macs', 'n_params']:
            if hasattr(module, attr):
                delattr(module, attr)

def get_model_info(model: nn.Module, prune_rate: float):
    """Paramsì™€ FLOPsë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    try:
        model.to('cpu').eval()
        dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to('cpu')
        
        macs, params = profile(model, inputs=(dummy_input, ), verbose=False)
        
        flops_g = macs / 1e9       # Giga FLOPs
        params_m = params / 1e6    # Million Parameters
        
        # ì¸¡ì • í›„ ë°˜ë“œì‹œ cleanup
        cleanup_thop_attributes(model)

        print(f"      [FLOPs] {params_m:.3f}M Params, {flops_g:.3f}G FLOPs")
        return params_m, flops_g
    except Exception as e:
        print(f"      [FLOPs] ì¸¡ì • ì‹¤íŒ¨: {e}")
        return 0.0, 0.0

def save_result_to_csv(data: dict):
    """ê²°ê³¼ë¥¼ CSV íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
    file_exists = os.path.isfile(RESULTS_FILE)
    
    with open(RESULTS_FILE, mode='a', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=data.keys())
        
        if not file_exists:
            writer.writeheader()
            
        writer.writerow(data)
    
    print(f"      [ì €ì¥] {data['Precision']}/{data['Prune Rate']} ê²°ê³¼ ì €ì¥ ì™„ë£Œ.")


def benchmark_speed(model_wrap: YOLO, name: str, precision: str, prune_rate: float, file_path=None, base_flops=None, base_params=None):
    """ëª¨ë¸ì˜ ìš©ëŸ‰, ì†ë„(FPS/Latency)ë¥¼ ì¸¡ì •í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤."""
    print(f"   ğŸ‘‰ ì¸¡ì • ì¤‘: {name} ({precision}, Prune:{prune_rate})")

    # 1. ìš©ëŸ‰ ì¸¡ì •
    size_mb = 0
    if file_path and os.path.exists(file_path):
        if os.path.isdir(file_path): 
            size_mb = sum(os.path.getsize(os.path.join(dp, f)) for dp, _, fn in os.walk(file_path) for f in fn) / (1024**2)
        else:
            size_mb = os.path.getsize(file_path) / (1024**2)
    
    # 2. FLOPs / Params (PyTorch ëª¨ë¸ì¸ ê²½ìš°ë§Œ ì¬ì¸¡ì •)
    params_m, flops_g = 0.0, 0.0
    
    # Pruned ëª¨ë¸ì€ FLOPsê°€ ë³€í–ˆìœ¼ë¯€ë¡œ ì¬ì¸¡ì • (ë‹¨, .engine íŒŒì¼ì€ ì•ˆ ë¨)
    if file_path and str(file_path).endswith('.pt'):
        if hasattr(model_wrap, 'model') and isinstance(model_wrap.model, nn.Module):
            params_m, flops_g = get_model_info(model_wrap.model, prune_rate)
        
    # Quantization ëª¨ë¸ì€ ì´ë¡ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    elif base_params and base_flops:
        params_m, flops_g = base_params, base_flops


    # 3. ì†ë„ ì¸¡ì • (Warmup + Test)
    try:
        dummy_img = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
        
        # Warmup (5íšŒ)
        for _ in range(5):
            model_wrap.predict(dummy_img, imgsz=IMG_SIZE, verbose=False, device='cpu')

        # Test (10íšŒ í‰ê· )
        t_start = time.time()
        for _ in range(10):
            model_wrap.predict(dummy_img, imgsz=IMG_SIZE, verbose=False, device='cpu')
        t_end = time.time()
        
        avg_time = (t_end - t_start) / 10
        avg_latency = avg_time * 1000
        fps = 1.0 / avg_time
        
        print(f"      âœ… ê²°ê³¼: {fps:.1f} FPS | {size_mb:.2f} MB")

        # 4. CSV ì €ì¥
        save_result_to_csv({
            'Timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
            'Precision': precision,
            'Prune Rate': prune_rate,
            'Params(M)': round(params_m, 3),
            'FLOPs(G)': round(flops_g, 3),
            'FPS_App': round(fps, 2),
            'Latency(ms)_App': round(avg_latency, 2),
            'Size(MB)': round(size_mb, 2)
        })
        
    except Exception as e:
        print(f"      âŒ ì¸¡ì • ì‹¤íŒ¨: {str(e)[:50]}")
        save_result_to_csv({
            'Timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
            'Precision': precision,
            'Prune Rate': prune_rate,
            'Params(M)': round(params_m, 3),
            'FLOPs(G)': round(flops_g, 3),
            'FPS_App': "Error",
            'Latency(ms)_App': "Error",
            'Size(MB)': round(size_mb, 2)
        })

# =========================================================
# ğŸ¯ MAIN EXECUTION
# =========================================================
# =========================================================
# ğŸ¯ MAIN EXECUTION (ìˆ˜ì •ë¨)
# =========================================================
def main():
    print("="*70)
    print("ğŸš€ [í†µí•© ë²¤ì¹˜ë§ˆí¬] íŒŒì¼ ìƒì„±, FLOPs ì¸¡ì •, ì†ë„ ì¸¡ì •ì„ í•œë²ˆì— ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    print("="*70)
    print("âš ï¸ ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¡œì»¬ PC/Macì—ì„œ ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")

    if not ORIGINAL_MODEL_PATH.exists():
         raise FileNotFoundError(f"ê¸°ë°˜ ëª¨ë¸ íŒŒì¼({ORIGINAL_MODEL_NAME})ì„ '{MODELS_DIR}'ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 0. Base Model ë¡œë“œ ë° FLOPs ê¸°ì¤€ê°’ ì„¤ì •
    yolo_base = YOLO(ORIGINAL_MODEL_PATH)
    base_params, base_flops = get_model_info(yolo_base.model, 0.0)
    
    print("\n[Step 0] ê¸°ë³¸ ëª¨ë¸ ì¸¡ì • (Baseline)")
    benchmark_speed(yolo_base, "Base Model", "fp32", 0.0, ORIGINAL_MODEL_PATH, base_params, base_flops)

    
    # --- ì‹¤í—˜ ëª©ë¡ ---
    prune_rates = [0.3, 0.5, 0.7]
    quantization_formats = ["coreml", "tflite"] # INT8 ì¸¡ì •

    # 1. Structured Pruning (ê°€ì§€ì¹˜ê¸° ëª¨ë¸ ìƒì„± ë° ì¸¡ì •)
    if HAS_TP:
        print("\n[Step 1] Structured Pruning ëª¨ë¸ ìƒì„± ë° ì¸¡ì •...")
        for rate in prune_rates:
            # ğŸš¨ FIX: Pruning ì‹¤íŒ¨ ì‹œë¥¼ ëŒ€ë¹„í•˜ì—¬ ë³€ìˆ˜ ì´ˆê¸°í™” (Base ê°’ìœ¼ë¡œ ì„¤ì •)
            pruned_params, pruned_flops = base_params, base_flops 
            
            prune_pct = int(rate * 100)
            save_path_tmp = MODELS_DIR / f"yolo11n_hand_pose_pruned_s_{prune_pct}_tmp.pt"
            save_path_final = MODELS_DIR / f"yolo11n_hand_pose_pruned_s_{prune_pct}.pt"
            
            # 1-1. ëª¨ë¸ ìƒì„± ë° ê°€ì§€ì¹˜ê¸°
            if not save_path_final.exists():
                print(f"   -> {rate} ëª¨ë¸ ìƒì„± ì¤‘...")
                
                # --- 1. ì›ë³¸ ëª¨ë¸ ë¡œë“œ ---
                yolo_tmp = YOLO(ORIGINAL_MODEL_PATH)
                model_raw = yolo_tmp.model # PyTorch Module
                
                try:
                    # --- 2. Pruning ì ìš© (ë§ˆìŠ¤í¬ ìƒì„±) ---
                    example_inputs = torch.randn(1, 3, 640, 640).to('cpu')
                    imp = tp.importance.MagnitudeImportance(p=1)
                    ignored_layers = []
                    for m in model_raw.modules():
                        # YOLO í—¤ë“œ ë ˆì´ì–´ ì œì™¸ ë¡œì§
                        if isinstance(m, torch.nn.Linear) and m.out_features == model_raw.head.nc:
                            ignored_layers.append(m)
                    
                    pruner = tp.pruner.MagnitudePruner(
                        model_raw, example_inputs, importance=imp, iterative_steps=1, pruning_ratio=rate, ignored_layers=ignored_layers
                    )
                    pruner.step()
                    
                    
                    # --- 3. FLOPs/Params ì¸¡ì • (ì„±ê³µí•˜ë©´ ë³€ìˆ˜ ì—…ë°ì´íŠ¸) ---
                    pruned_params, pruned_flops = get_model_info(model_raw, rate) 
                    print(f"   -> ì´ë¡  ë³µì¡ë„ ì¸¡ì • ì„±ê³µ: {pruned_params:.3f}M Params, {pruned_flops:.3f}G FLOPs")
                    
                    
                    # --- 4. ë§ˆìŠ¤í¬ ì œê±° ë° ìµœì¢… ì €ì¥ ---
                    for name, m in model_raw.named_modules():
                        if hasattr(m, "weight_mask"):
                            # ë§ˆìŠ¤í¬ ì˜êµ¬ ì œê±°
                            prune.remove(m, "weight")
                    
                    # ì›ë³¸ YOLO íŒŒì¼ì— ë®ì–´ì”Œì›Œ ì €ì¥
                    torch.save(model_raw, save_path_tmp)
                    
                    # YOLO ê°ì²´ë¥¼ ë‹¤ì‹œ ë¡œë“œí•˜ê³  Ultralyticsì˜ save()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”íƒ€ë°ì´í„° í¬í•¨
                    YOLO(save_path_tmp).save(save_path_final)
                    
                    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    os.remove(save_path_tmp)
                    print(f"   -> {save_path_final.name} ì €ì¥ ì™„ë£Œ.")


                except Exception as e:
                    print(f"   âŒ Pruning ì‹¤íŒ¨ ë° ìŠ¤í‚µ: {e}")
                    # ì‹¤íŒ¨í•œ ê²½ìš° CSVì— ê¸°ë¡ (0 ê°’) -> Baseline ê°’ì€ ìœ ì§€ë˜ì§€ë§Œ, ì†ë„ ì¸¡ì •ì€ ê±´ë„ˆëœ€
                    save_result_to_csv({
                        'Timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
                        'Precision': 'fp32', 'Prune Rate': rate,
                        'Params(M)': base_params, 'FLOPs(G)': base_flops, # ì‹¤íŒ¨í–ˆìœ¼ë¯€ë¡œ ë² ì´ìŠ¤ë¼ì¸ ê°’ ê¸°ë¡
                        'FPS_App': "Error (Gen)", 'Latency(ms)_App': "Error (Gen)",
                        'Size(MB)': 0.0
                    })
                    continue # ì†ë„ ì¸¡ì • ê±´ë„ˆë›°ê¸°
            
            # 1-2. ì¸¡ì • (ìƒì„±ëœ ìµœì¢… íŒŒì¼ì„ ë‹¤ì‹œ ë¡œë“œí•˜ì—¬ ì†ë„ ì¸¡ì •)
            pruned_model = YOLO(save_path_final)
            benchmark_speed(pruned_model, f"Pruned ({prune_pct}%)", "fp32", rate, save_path_final, pruned_params, pruned_flops)

    # 2. Quantization (ì–‘ìí™” ëª¨ë¸ ìƒì„± ë° ì¸¡ì •)
    print("\n[Step 2] Quantization ëª¨ë¸ ìƒì„± ë° ì¸¡ì •...")
    for fmt in quantization_formats:
        export_path = MODELS_DIR / f"yolo11n_hand_pose_int8.{fmt}"

        # 2-1. íŒŒì¼ ìƒì„±
        if not export_path.exists() and fmt != "coreml":
             try:
                # CoreML íŒŒì¼ì€ export ì´ë¦„ì´ ë‹¬ë¼ ë‹¤ì‹œ ì •ì˜í•´ì•¼ í•¨
                if fmt == 'coreml':
                    YOLO(ORIGINAL_MODEL_PATH).export(format=fmt, int8=True, nms=True)
                else:
                    YOLO(ORIGINAL_MODEL_PATH).export(format=fmt, int8=True, imgsz=IMG_SIZE)
                
                # CoreML/TFLite ê²½ë¡œ ë³´ì •
                if fmt == 'coreml':
                    export_path = ORIGINAL_MODEL_PATH.parent / ORIGINAL_MODEL_NAME.replace('.pt', '.mlpackage')
                elif fmt == 'tflite':
                    tflite_folder = ORIGINAL_MODEL_PATH.parent / ORIGINAL_MODEL_NAME.replace('.pt', '_saved_model')
                    export_path = tflite_folder / f"{ORIGINAL_MODEL_NAME.replace('.pt', '_int8.tflite')}"
                
                if not export_path.exists(): 
                    print(f"   âŒ {fmt.upper()} INT8 ìƒì„±ë˜ì—ˆìœ¼ë‚˜ ìµœì¢… íŒŒì¼ ì°¾ê¸° ì‹¤íŒ¨.")
                    continue
                
             except Exception as e:
                print(f"   âŒ {fmt.upper()} INT8 ìƒì„± ì‹¤íŒ¨: {e}")
                continue

        # 2-2. ì¸¡ì •
        if export_path.exists():
            name = f"INT8 ({fmt.upper()})"
            
            yolo_export = YOLO(export_path, task='pose')
            
            # FLOPs/ParamsëŠ” Baseline ê°’ì„ ì‚¬ìš©
            benchmark_speed(yolo_export, name, "int8", 0.0, export_path, base_params, base_flops)
        else:
             print(f"   âŒ {fmt.upper()} INT8 ì¸¡ì • ìŠ¤í‚µ (íŒŒì¼ ì—†ìŒ)")


if __name__ == "__main__":
    main()
    print("\n" + "="*70)
    print(f"âœ… í†µí•© ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ: ëª¨ë“  ê²°ê³¼ê°€ {RESULTS_FILE}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("ì´ì œ ì´ CSV íŒŒì¼ê³¼ ëª¨ë¸ë“¤ì„ Jetson Nanoë¡œ ì˜®ê²¨ì„œ ì‹¤ì œ FPSë¥¼ ì¸¡ì •í•˜ì„¸ìš”.")
    print("="*70)